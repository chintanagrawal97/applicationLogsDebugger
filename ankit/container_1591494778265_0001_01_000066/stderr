SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/mnt/yarn/usercache/hadoop/filecache/10/__spark_libs__8474873730201561419.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/06/06 19:12:24 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 9329@ip-10-128-11-143
20/06/06 19:12:24 INFO SignalUtils: Registered signal handler for TERM
20/06/06 19:12:24 INFO SignalUtils: Registered signal handler for HUP
20/06/06 19:12:24 INFO SignalUtils: Registered signal handler for INT
20/06/06 19:12:25 INFO SecurityManager: Changing view acls to: yarn,hadoop
20/06/06 19:12:25 INFO SecurityManager: Changing modify acls to: yarn,hadoop
20/06/06 19:12:25 INFO SecurityManager: Changing view acls groups to: 
20/06/06 19:12:25 INFO SecurityManager: Changing modify acls groups to: 
20/06/06 19:12:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
20/06/06 19:12:25 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:42673 after 85 ms (0 ms spent in bootstraps)
20/06/06 19:12:25 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
20/06/06 19:12:25 INFO SecurityManager: Changing view acls to: yarn,hadoop
20/06/06 19:12:25 INFO SecurityManager: Changing modify acls to: yarn,hadoop
20/06/06 19:12:25 INFO SecurityManager: Changing view acls groups to: 
20/06/06 19:12:25 INFO SecurityManager: Changing modify acls groups to: 
20/06/06 19:12:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
20/06/06 19:12:25 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:42673 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:12:25 INFO DiskBlockManager: Created local directory at /mnt/yarn/usercache/hadoop/appcache/application_1591494778265_0001/blockmgr-73a0512a-7876-4e8e-9a90-a3f200ae4e6c
20/06/06 19:12:25 INFO MemoryStore: MemoryStore started with capacity 9.4 GB
20/06/06 19:12:25 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@ip-10-128-11-116.us-west-2.compute.internal:42673
20/06/06 19:12:25 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/06/06 19:12:25 INFO Executor: Starting executor ID 56 on host ip-10-128-11-143.us-west-2.compute.internal
20/06/06 19:12:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37033.
20/06/06 19:12:26 INFO NettyBlockTransferService: Server created on ip-10-128-11-143.us-west-2.compute.internal:37033
20/06/06 19:12:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/06/06 19:12:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(56, ip-10-128-11-143.us-west-2.compute.internal, 37033, None)
20/06/06 19:12:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(56, ip-10-128-11-143.us-west-2.compute.internal, 37033, None)
20/06/06 19:12:26 INFO BlockManager: external shuffle service port = 7337
20/06/06 19:12:26 INFO BlockManager: Registering executor with local external shuffle service.
20/06/06 19:12:26 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-143.us-west-2.compute.internal/10.128.11.143:7337 after 0 ms (0 ms spent in bootstraps)
20/06/06 19:12:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(56, ip-10-128-11-143.us-west-2.compute.internal, 37033, None)
20/06/06 19:12:26 INFO CoarseGrainedExecutorBackend: Got assigned task 3042
20/06/06 19:12:26 INFO CoarseGrainedExecutorBackend: Got assigned task 3043
20/06/06 19:12:26 INFO CoarseGrainedExecutorBackend: Got assigned task 3044
20/06/06 19:12:26 INFO CoarseGrainedExecutorBackend: Got assigned task 3045
20/06/06 19:12:26 INFO Executor: Running task 225.0 in stage 14.0 (TID 3043)
20/06/06 19:12:26 INFO Executor: Running task 224.0 in stage 14.0 (TID 3042)
20/06/06 19:12:26 INFO Executor: Running task 227.0 in stage 14.0 (TID 3045)
20/06/06 19:12:26 INFO Executor: Running task 226.0 in stage 14.0 (TID 3044)
20/06/06 19:12:26 INFO TorrentBroadcast: Started reading broadcast variable 19
20/06/06 19:12:26 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-143.us-west-2.compute.internal/10.128.11.143:38449 after 0 ms (0 ms spent in bootstraps)
20/06/06 19:12:26 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.6 KB, free 9.4 GB)
20/06/06 19:12:26 INFO TorrentBroadcast: Reading broadcast variable 19 took 145 ms
20/06/06 19:12:26 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 189.6 KB, free 9.4 GB)
20/06/06 19:12:26 INFO CodeGenerator: Code generated in 256.909365 ms
20/06/06 19:12:27 INFO CodeGenerator: Code generated in 12.199232 ms
20/06/06 19:12:27 INFO CodeGenerator: Code generated in 16.552386 ms
20/06/06 19:12:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=26/000001_0, range: 0-282585, partition values: [2017,6,26]
20/06/06 19:12:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=6/000006_0, range: 0-281725, partition values: [2019,6,6]
20/06/06 19:12:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=8/000003_0, range: 0-282176, partition values: [2017,7,8]
20/06/06 19:12:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=3/000008_0, range: 0-281342, partition values: [2019,3,3]
20/06/06 19:12:27 INFO TorrentBroadcast: Started reading broadcast variable 15
20/06/06 19:12:27 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 39.2 KB, free 9.4 GB)
20/06/06 19:12:27 INFO TorrentBroadcast: Reading broadcast variable 15 took 7 ms
20/06/06 19:12:27 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 595.0 KB, free 9.4 GB)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:179)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat$$anonfun$buildReaderWithPartitionValues$2.apply(OrcFileFormat.scala:174)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage43.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:80)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec$$anonfun$doExecute$1$$anonfun$3.apply(SortAggregateExec.scala:77)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:12:29 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:12:29 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:12:29 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:12:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=3/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281342, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=8/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282176, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=26/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282585, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=6/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281725, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:30 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:12:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=17/000006_0, range: 0-282581, partition values: [2018,3,17]
20/06/06 19:12:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=17/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282581, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=21/000014_0, range: 0-281724, partition values: [2019,1,21]
20/06/06 19:12:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000008_0, range: 0-282162, partition values: [2018,12,11]
20/06/06 19:12:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=21/000014_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281724, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282162, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=10/000010_0, range: 0-281308, partition values: [2020,5,10]
20/06/06 19:12:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=10/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281308, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=31/000007_0, range: 0-281296, partition values: [2019,7,31]
20/06/06 19:13:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=31/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281296, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:16 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=18/000012_0, range: 0-282136, partition values: [2018,6,18]
20/06/06 19:13:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=18/000012_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282136, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=28/000010_0, range: 0-281688, partition values: [2019,1,28]
20/06/06 19:13:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=28/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281688, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=19/000005_0, range: 0-282564, partition values: [2018,10,19]
20/06/06 19:13:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=19/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282564, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000008_0, range: 0-281288, partition values: [2019,7,28]
20/06/06 19:13:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281288, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=28/000008_0, range: 0-282135, partition values: [2019,6,28]
20/06/06 19:13:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=28/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282135, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=15/000011_0, range: 0-281286, partition values: [2018,8,15]
20/06/06 19:13:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=15/000011_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281286, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=28/000007_0, range: 0-282562, partition values: [2019,6,28]
20/06/06 19:13:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=28/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282562, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=2/000005_0, range: 0-281684, partition values: [2019,5,2]
20/06/06 19:14:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=2/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281684, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=16/000013_0, range: 0-282135, partition values: [2018,9,16]
20/06/06 19:14:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=16/000013_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282135, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=10/000007_0, range: 0-282556, partition values: [2018,4,10]
20/06/06 19:14:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=10/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282556, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:16 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=7/000014_0, range: 0-281639, partition values: [2020,5,7]
20/06/06 19:14:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=7/000014_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281639, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=8/000011_0, range: 0-281278, partition values: [2018,10,8]
20/06/06 19:14:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=8/000011_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281278, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=28/000000_0, range: 0-282111, partition values: [2018,2,28]
20/06/06 19:14:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=28/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282111, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:38 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=28/000010_0, range: 0-281624, partition values: [2018,4,28]
20/06/06 19:14:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=28/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281624, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=1/000007_0, range: 0-281256, partition values: [2019,8,1]
20/06/06 19:14:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=1/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281256, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=4/000206_0, range: 0-282554, partition values: [2017,1,4]
20/06/06 19:14:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=4/000206_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 282554, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:14:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=13/000000_0, range: 0-282546, partition values: [2019,9,13]
20/06/06 19:14:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=13/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282546, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=24/000006_0, range: 0-281236, partition values: [2019,5,24]
20/06/06 19:14:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=24/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281236, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=12/000002_0, range: 0-282544, partition values: [2017,6,12]
20/06/06 19:15:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=12/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282544, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=20/000000_0, range: 0-282102, partition values: [2017,5,20]
20/06/06 19:15:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=20/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282102, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=6/000013_0, range: 0-281623, partition values: [2020,4,6]
20/06/06 19:15:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=6/000013_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281623, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:16 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=19/000008_0, range: 0-281209, partition values: [2018,5,19]
20/06/06 19:15:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=19/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281209, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:25 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=31/000007_0, range: 0-282510, partition values: [2018,7,31]
20/06/06 19:15:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=31/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282510, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=17/000003_0, range: 0-282092, partition values: [2019,11,17]
20/06/06 19:15:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=17/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282092, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=11/000005_0, range: 0-281595, partition values: [2018,9,11]
20/06/06 19:15:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=11/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281595, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=2/000010_0, range: 0-282085, partition values: [2019,6,2]
20/06/06 19:15:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=2/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282085, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=12/000002_0, range: 0-281206, partition values: [2019,2,12]
20/06/06 19:15:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=12/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281206, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=8/000000_0, range: 0-282497, partition values: [2017,4,8]
20/06/06 19:15:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=8/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282497, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=22/000015_0, range: 0-281562, partition values: [2018,7,22]
20/06/06 19:15:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=22/000015_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281562, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:05 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=12/000007_0, range: 0-282066, partition values: [2019,8,12]
20/06/06 19:16:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=12/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282066, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=8/000006_0, range: 0-282497, partition values: [2017,8,8]
20/06/06 19:16:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=8/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282497, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=22/000005_0, range: 0-282062, partition values: [2019,6,22]
20/06/06 19:16:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=22/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282062, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=27/000012_0, range: 0-281548, partition values: [2018,8,27]
20/06/06 19:16:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=29/000001_0, range: 0-282476, partition values: [2020,1,29]
20/06/06 19:16:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=27/000012_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281548, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=29/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282476, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000007_0, range: 0-281201, partition values: [2019,7,28]
20/06/06 19:16:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281201, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=7/000005_0, range: 0-282058, partition values: [2019,12,7]
20/06/06 19:16:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=7/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282058, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=23/000013_0, range: 0-282445, partition values: [2020,5,23]
20/06/06 19:16:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=23/000013_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282445, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=27/000003_0, range: 0-281197, partition values: [2018,2,27]
20/06/06 19:16:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=27/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281197, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=24/000008_0, range: 0-281542, partition values: [2019,3,24]
20/06/06 19:16:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=24/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281542, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=4/000007_0, range: 0-282039, partition values: [2018,4,4]
20/06/06 19:16:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=4/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282039, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=24/000000_0, range: 0-282427, partition values: [2018,5,24]
20/06/06 19:17:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=20/000005_0, range: 0-281541, partition values: [2019,8,20]
20/06/06 19:17:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=24/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282427, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=20/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281541, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=28/000006_0, range: 0-281183, partition values: [2018,9,28]
20/06/06 19:17:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=28/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281183, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=22/000001_0, range: 0-281533, partition values: [2017,4,22]
20/06/06 19:17:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=22/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281533, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=22/000213_0, range: 0-282038, partition values: [2016,12,22]
20/06/06 19:17:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=22/000213_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 282038, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:17:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=19/000005_0, range: 0-281996, partition values: [2017,7,19]
20/06/06 19:17:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=19/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281996, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=25/000014_0, range: 0-281528, partition values: [2018,7,25]
20/06/06 19:17:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=25/000014_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281528, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=28/000001_0, range: 0-282427, partition values: [2019,2,28]
20/06/06 19:17:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=28/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282427, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=11/000017_0, range: 0-281163, partition values: [2020,5,11]
20/06/06 19:17:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=11/000017_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281163, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=4/000215_0, range: 0-281983, partition values: [2016,12,4]
20/06/06 19:17:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=4/000215_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 281983, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:17:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=19/000000_0, range: 0-281940, partition values: [2019,3,19]
20/06/06 19:17:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=19/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281940, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=11/000007_0, range: 0-282405, partition values: [2019,7,11]
20/06/06 19:18:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=11/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282405, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=15/000000_0, range: 0-281162, partition values: [2017,1,15]
20/06/06 19:18:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=15/000013_0, range: 0-281526, partition values: [2020,5,15]
20/06/06 19:18:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=15/000013_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281526, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=15/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 281162, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:18:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=20/000012_0, range: 0-281931, partition values: [2018,10,20]
20/06/06 19:18:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=20/000012_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281931, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:25 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=5/000001_0, range: 0-281160, partition values: [2017,6,5]
20/06/06 19:18:25 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=5/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281160, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:25 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=8/000007_0, range: 0-282374, partition values: [2019,8,8]
20/06/06 19:18:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=8/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282374, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=2/000007_0, range: 0-281525, partition values: [2019,3,2]
20/06/06 19:18:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=2/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281525, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=12/000000_0, range: 0-281134, partition values: [2019,9,12]
20/06/06 19:18:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=2/000012_0, range: 0-281922, partition values: [2018,4,2]
20/06/06 19:18:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=12/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281134, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=2/000012_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281922, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=23/000006_0, range: 0-282349, partition values: [2019,7,23]
20/06/06 19:18:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=23/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282349, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=21/000007_0, range: 0-281512, partition values: [2019,12,21]
20/06/06 19:18:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=21/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281512, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000009_0, range: 0-281118, partition values: [2018,12,11]
20/06/06 19:19:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281118, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=3/000005_0, range: 0-282328, partition values: [2019,6,3]
20/06/06 19:19:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=3/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282328, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=1/000006_0, range: 0-281473, partition values: [2018,8,1]
20/06/06 19:19:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=1/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281473, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=17/000007_0, range: 0-281913, partition values: [2018,3,17]
20/06/06 19:19:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=17/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281913, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=4/000008_0, range: 0-282327, partition values: [2017,8,4]
20/06/06 19:19:22 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=4/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282327, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:22 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=24/000005_0, range: 0-281100, partition values: [2019,5,24]
20/06/06 19:19:33 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=24/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281100, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:33 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:33 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=28/000007_0, range: 0-282324, partition values: [2018,10,28]
20/06/06 19:19:33 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=28/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282324, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:33 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=2/000020_0, range: 0-281454, partition values: [2018,12,2]
20/06/06 19:19:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=2/000020_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281454, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=25/000004_0, range: 0-281879, partition values: [2018,5,25]
20/06/06 19:19:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=29/000005_0, range: 0-281077, partition values: [2018,3,29]
20/06/06 19:19:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=25/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281879, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=29/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281077, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=11/000002_0, range: 0-282320, partition values: [2019,4,11]
20/06/06 19:20:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=11/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282320, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=13/000014_0, range: 0-282320, partition values: [2019,1,13]
20/06/06 19:20:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=13/000014_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282320, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=27/000004_0, range: 0-281876, partition values: [2018,1,27]
20/06/06 19:20:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=27/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281876, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=12/000006_0, range: 0-281076, partition values: [2019,4,12]
20/06/06 19:20:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=12/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281076, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=13/000012_0, range: 0-281451, partition values: [2019,4,13]
20/06/06 19:20:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=13/000012_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281451, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=10/000000_0, range: 0-281070, partition values: [2020,3,10]
20/06/06 19:20:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=10/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281070, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=19/000011_0, range: 0-281449, partition values: [2019,4,19]
20/06/06 19:20:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=19/000011_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281449, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=3/000014_0, range: 0-282316, partition values: [2019,1,3]
20/06/06 19:21:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=3/000014_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282316, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=8/000006_0, range: 0-281444, partition values: [2019,5,8]
20/06/06 19:21:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=8/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281444, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=8/000010_0, range: 0-281871, partition values: [2018,10,8]
20/06/06 19:21:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=8/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281871, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=5/000008_0, range: 0-281065, partition values: [2018,10,5]
20/06/06 19:21:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=5/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281065, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=20/000010_0, range: 0-281439, partition values: [2019,6,20]
20/06/06 19:21:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=20/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281439, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=27/000004_0, range: 0-281064, partition values: [2018,4,27]
20/06/06 19:21:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=27/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281064, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=24/000017_0, range: 0-281868, partition values: [2018,11,24]
20/06/06 19:21:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=24/000017_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281868, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=3/000015_0, range: 0-282308, partition values: [2020,4,3]
20/06/06 19:21:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=3/000015_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282308, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=10/000005_0, range: 0-281422, partition values: [2017,8,10]
20/06/06 19:21:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=10/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281422, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=24/000014_0, range: 0-281412, partition values: [2018,6,24]
20/06/06 19:21:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=24/000014_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281412, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:00 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=4/000009_0, range: 0-282307, partition values: [2018,6,4]
20/06/06 19:22:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=4/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282307, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=7/000013_0, range: 0-281055, partition values: [2019,7,7]
20/06/06 19:22:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=7/000013_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281055, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=8/000004_0, range: 0-281830, partition values: [2019,2,8]
20/06/06 19:22:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=8/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281830, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=18/000011_0, range: 0-281405, partition values: [2019,5,18]
20/06/06 19:22:20 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=18/000011_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281405, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:20 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=14/000006_0, range: 0-281047, partition values: [2019,12,14]
20/06/06 19:22:22 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=14/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281047, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:22 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=24/000006_0, range: 0-282257, partition values: [2019,7,24]
20/06/06 19:22:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=24/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282257, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=1/000017_0, range: 0-281399, partition values: [2020,5,1]
20/06/06 19:22:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=1/000017_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281399, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=25/000003_0, range: 0-281047, partition values: [2017,6,25]
20/06/06 19:22:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=25/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281047, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=6/day=14/000211_0, range: 0-281819, partition values: [2016,6,14]
20/06/06 19:22:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=6/day=14/000211_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 281819, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:22:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=27/000010_0, range: 0-281806, partition values: [2018,10,27]
20/06/06 19:22:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=27/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281806, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=12/000006_0, range: 0-282239, partition values: [2018,5,12]
20/06/06 19:22:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=12/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282239, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=9/000007_0, range: 0-281378, partition values: [2019,1,9]
20/06/06 19:22:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=9/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281378, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=14/000009_0, range: 0-281024, partition values: [2019,1,14]
20/06/06 19:23:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=14/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281024, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=6/000007_0, range: 0-281793, partition values: [2019,8,6]
20/06/06 19:23:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=6/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281793, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=20/000002_0, range: 0-282222, partition values: [2018,1,20]
20/06/06 19:23:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=20/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282222, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:33 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=28/000010_0, range: 0-281364, partition values: [2018,7,28]
20/06/06 19:23:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=28/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281364, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=27/000006_0, range: 0-281763, partition values: [2018,11,27]
20/06/06 19:23:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=27/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281763, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=3/000005_0, range: 0-281007, partition values: [2019,8,3]
20/06/06 19:23:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=3/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281007, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=11/000013_0, range: 0-281002, partition values: [2018,2,11]
20/06/06 19:23:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=11/000013_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281002, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=13/000005_0, range: 0-282217, partition values: [2018,5,13]
20/06/06 19:24:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=13/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 282217, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=5/000004_0, range: 0-281343, partition values: [2019,4,5]
20/06/06 19:24:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=5/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281343, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=14/000006_0, range: 0-281735, partition values: [2018,12,14]
20/06/06 19:24:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=14/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 281735, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:22 INFO CodeGenerator: Code generated in 11.645873 ms
20/06/06 19:24:22 INFO CodeGenerator: Code generated in 14.667693 ms
20/06/06 19:24:22 INFO CodeGenerator: Code generated in 7.006375 ms
20/06/06 19:24:22 INFO CodeGenerator: Code generated in 9.154304 ms
20/06/06 19:24:22 INFO CodeGenerator: Code generated in 13.664721 ms
20/06/06 19:24:23 INFO Executor: Finished task 226.0 in stage 14.0 (TID 3044). 2592 bytes result sent to driver
20/06/06 19:24:23 INFO CoarseGrainedExecutorBackend: Got assigned task 4281
20/06/06 19:24:23 INFO Executor: Running task 1463.0 in stage 14.0 (TID 4281)
20/06/06 19:24:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=25/003643_0, range: 0-52649, partition values: [2016,5,25]
20/06/06 19:24:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=25/003643_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 52649, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=10/000042_0, range: 0-52644, partition values: [2018,2,10]
20/06/06 19:24:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=10/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52644, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=15/000032_0, range: 0-52641, partition values: [2019,7,15]
20/06/06 19:24:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=15/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52641, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:31 INFO Executor: Finished task 227.0 in stage 14.0 (TID 3045). 2549 bytes result sent to driver
20/06/06 19:24:31 INFO CoarseGrainedExecutorBackend: Got assigned task 4294
20/06/06 19:24:31 INFO Executor: Running task 1476.0 in stage 14.0 (TID 4294)
20/06/06 19:24:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=31/000029_0, range: 0-51588, partition values: [2017,3,31]
20/06/06 19:24:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=31/000029_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 51588, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=19/000028_0, range: 0-52641, partition values: [2017,4,19]
20/06/06 19:24:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=19/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52641, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=18/000041_0, range: 0-51585, partition values: [2019,5,18]
20/06/06 19:24:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=18/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51585, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=26/000024_0, range: 0-52639, partition values: [2017,9,26]
20/06/06 19:24:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=26/000024_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52639, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=16/000030_0, range: 0-51584, partition values: [2017,11,16]
20/06/06 19:24:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=16/000030_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51584, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:37 INFO Executor: Finished task 225.0 in stage 14.0 (TID 3043). 2549 bytes result sent to driver
20/06/06 19:24:37 INFO CoarseGrainedExecutorBackend: Got assigned task 4305
20/06/06 19:24:37 INFO Executor: Running task 1487.0 in stage 14.0 (TID 4305)
20/06/06 19:24:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=8/000026_0, range: 0-50660, partition values: [2017,11,8]
20/06/06 19:24:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=8/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50660, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:38 INFO Executor: Finished task 224.0 in stage 14.0 (TID 3042). 2549 bytes result sent to driver
20/06/06 19:24:38 INFO CoarseGrainedExecutorBackend: Got assigned task 4308
20/06/06 19:24:38 INFO Executor: Running task 1490.0 in stage 14.0 (TID 4308)
20/06/06 19:24:38 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=17/000040_0, range: 0-50390, partition values: [2019,2,17]
20/06/06 19:24:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=17/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50390, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=8/000027_0, range: 0-52639, partition values: [2020,1,8]
20/06/06 19:24:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=8/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52639, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=14/003737_0, range: 0-50388, partition values: [2016,7,14]
20/06/06 19:24:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=1/003647_0, range: 0-51583, partition values: [2017,1,1]
20/06/06 19:24:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=14/003737_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50388, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=1/003647_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 51583, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=13/000021_0, range: 0-50660, partition values: [2017,9,13]
20/06/06 19:24:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=5/000031_0, range: 0-50388, partition values: [2019,4,5]
20/06/06 19:24:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=3/000035_0, range: 0-52633, partition values: [2017,5,3]
20/06/06 19:24:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=13/000021_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50660, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=3/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52633, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=5/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50388, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=11/003690_0, range: 0-51582, partition values: [2016,4,11]
20/06/06 19:24:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=11/003690_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 51582, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=6/000036_0, range: 0-51581, partition values: [2019,4,6]
20/06/06 19:24:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=6/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51581, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=4/000031_0, range: 0-52633, partition values: [2019,4,4]
20/06/06 19:24:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=12/000037_0, range: 0-50385, partition values: [2020,1,12]
20/06/06 19:24:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=4/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52633, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=12/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50385, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=23/003691_0, range: 0-51581, partition values: [2016,4,23]
20/06/06 19:24:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=23/003691_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 51581, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=9/000030_0, range: 0-51578, partition values: [2017,10,9]
20/06/06 19:24:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=16/000035_0, range: 0-50655, partition values: [2019,4,16]
20/06/06 19:24:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=9/000030_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51578, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=16/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50655, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=1/000038_0, range: 0-52632, partition values: [2018,9,1]
20/06/06 19:24:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=20/000032_0, range: 0-50383, partition values: [2017,12,20]
20/06/06 19:24:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=1/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52632, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=20/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50383, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=16/000024_0, range: 0-50652, partition values: [2017,10,16]
20/06/06 19:24:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=16/000024_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50652, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=5/000027_0, range: 0-51577, partition values: [2017,9,5]
20/06/06 19:24:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=5/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51577, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=2/000038_0, range: 0-52630, partition values: [2018,3,2]
20/06/06 19:24:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=2/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52630, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=15/000034_0, range: 0-50648, partition values: [2017,6,15]
20/06/06 19:24:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=9/day=24/003738_0, range: 0-50382, partition values: [2016,9,24]
20/06/06 19:24:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=9/day=24/003738_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50382, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=15/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50648, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=28/000039_0, range: 0-50378, partition values: [2019,6,28]
20/06/06 19:24:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=28/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50378, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=24/000032_0, range: 0-51571, partition values: [2019,8,24]
20/06/06 19:25:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=24/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51571, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=16/000031_0, range: 0-50647, partition values: [2019,12,16]
20/06/06 19:25:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=16/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50647, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=1/003644_0, range: 0-52630, partition values: [2016,2,1]
20/06/06 19:25:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=3/day=25/003699_0, range: 0-50367, partition values: [2016,3,25]
20/06/06 19:25:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=1/003644_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 52630, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=3/day=25/003699_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50367, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=1/000038_0, range: 0-52630, partition values: [2020,4,1]
20/06/06 19:25:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=1/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52630, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=31/000042_0, range: 0-50366, partition values: [2019,3,31]
20/06/06 19:25:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=31/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50366, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=12/000042_0, range: 0-51569, partition values: [2018,6,12]
20/06/06 19:25:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=12/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51569, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=5/000039_0, range: 0-50644, partition values: [2019,5,5]
20/06/06 19:25:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=5/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50644, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=3/day=21/003739_0, range: 0-50363, partition values: [2016,3,21]
20/06/06 19:25:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=1/000030_0, range: 0-52628, partition values: [2017,9,1]
20/06/06 19:25:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=3/day=21/003739_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50363, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=1/000030_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52628, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=11/000031_0, range: 0-50362, partition values: [2017,12,11]
20/06/06 19:25:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=11/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50362, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=13/000035_0, range: 0-50636, partition values: [2018,11,13]
20/06/06 19:25:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=13/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50636, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=3/000039_0, range: 0-51563, partition values: [2019,6,3]
20/06/06 19:25:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=3/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51563, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=10/000033_0, range: 0-52628, partition values: [2019,3,10]
20/06/06 19:25:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=10/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52628, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=24/000038_0, range: 0-51556, partition values: [2019,2,24]
20/06/06 19:25:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=24/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51556, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=14/000039_0, range: 0-50635, partition values: [2018,7,14]
20/06/06 19:25:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=14/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50635, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=10/000033_0, range: 0-52626, partition values: [2018,5,10]
20/06/06 19:25:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=10/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52626, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=21/000040_0, range: 0-50362, partition values: [2019,1,21]
20/06/06 19:25:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=21/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50362, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=28/000037_0, range: 0-51555, partition values: [2019,4,28]
20/06/06 19:25:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=14/000015_0, range: 0-50631, partition values: [2017,8,14]
20/06/06 19:25:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=28/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51555, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=14/000015_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50631, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=15/000033_0, range: 0-51553, partition values: [2017,5,15]
20/06/06 19:25:20 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=15/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51553, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:20 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=9/000030_0, range: 0-50362, partition values: [2020,1,9]
20/06/06 19:25:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=2/000033_0, range: 0-52624, partition values: [2019,5,2]
20/06/06 19:25:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=9/000030_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50362, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=2/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52624, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=4/000043_0, range: 0-50626, partition values: [2018,6,4]
20/06/06 19:25:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=4/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50626, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=12/000036_0, range: 0-52609, partition values: [2018,11,12]
20/06/06 19:25:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=12/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52609, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=10/000028_0, range: 0-51549, partition values: [2017,2,10]
20/06/06 19:25:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=10/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 51549, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=11/000032_0, range: 0-50361, partition values: [2020,3,11]
20/06/06 19:25:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=11/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50361, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=25/000028_0, range: 0-51548, partition values: [2017,10,25]
20/06/06 19:25:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=25/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51548, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=2/000031_0, range: 0-50622, partition values: [2017,9,2]
20/06/06 19:25:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=2/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50622, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=11/000027_0, range: 0-50359, partition values: [2019,10,11]
20/06/06 19:25:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=11/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50359, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=1/000040_0, range: 0-52607, partition values: [2019,1,1]
20/06/06 19:25:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=1/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52607, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=3/000036_0, range: 0-50621, partition values: [2018,12,3]
20/06/06 19:25:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=3/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50621, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=18/000034_0, range: 0-50358, partition values: [2018,1,18]
20/06/06 19:25:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=18/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50358, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=1/000038_0, range: 0-51542, partition values: [2020,2,1]
20/06/06 19:25:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=1/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51542, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=1/000037_0, range: 0-52605, partition values: [2017,8,1]
20/06/06 19:25:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=1/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52605, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=23/000033_0, range: 0-51541, partition values: [2017,5,23]
20/06/06 19:25:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=23/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51541, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=2/000044_0, range: 0-50621, partition values: [2018,12,2]
20/06/06 19:25:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=2/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50621, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=7/000029_0, range: 0-52602, partition values: [2019,3,7]
20/06/06 19:25:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=7/000029_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52602, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:38 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=10/000041_0, range: 0-50357, partition values: [2020,5,10]
20/06/06 19:25:39 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=10/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50357, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:39 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=28/000036_0, range: 0-51541, partition values: [2019,4,28]
20/06/06 19:25:39 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=28/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51541, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:39 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=3/000025_0, range: 0-52600, partition values: [2019,12,3]
20/06/06 19:25:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=3/000025_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52600, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=17/000039_0, range: 0-51532, partition values: [2020,5,17]
20/06/06 19:25:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=17/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51532, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=16/000034_0, range: 0-50354, partition values: [2018,5,16]
20/06/06 19:25:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=16/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50354, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=15/000033_0, range: 0-50612, partition values: [2017,4,15]
20/06/06 19:25:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=15/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50612, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=19/000034_0, range: 0-52599, partition values: [2017,3,19]
20/06/06 19:25:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=19/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 52599, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=17/000040_0, range: 0-51532, partition values: [2018,3,17]
20/06/06 19:25:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=17/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51532, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000036_0, range: 0-50611, partition values: [2019,7,28]
20/06/06 19:25:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50611, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=8/day=30/003645_0, range: 0-52597, partition values: [2016,8,30]
20/06/06 19:25:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=8/day=30/003645_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 52597, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=11/000035_0, range: 0-52595, partition values: [2019,1,11]
20/06/06 19:25:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=11/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52595, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=13/000027_0, range: 0-50349, partition values: [2020,1,13]
20/06/06 19:25:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=13/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50349, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=6/000035_0, range: 0-50611, partition values: [2018,9,6]
20/06/06 19:25:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=6/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50611, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=20/000038_0, range: 0-51531, partition values: [2018,8,20]
20/06/06 19:25:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=14/000033_0, range: 0-50344, partition values: [2018,9,14]
20/06/06 19:25:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=20/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51531, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=14/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50344, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=14/000016_0, range: 0-50606, partition values: [2017,8,14]
20/06/06 19:25:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=26/000035_0, range: 0-52593, partition values: [2019,8,26]
20/06/06 19:25:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=14/000016_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50606, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=26/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52593, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=6/003740_0, range: 0-50336, partition values: [2016,1,6]
20/06/06 19:25:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=6/003740_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50336, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=9/000038_0, range: 0-51531, partition values: [2017,12,9]
20/06/06 19:25:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=9/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51531, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=21/000031_0, range: 0-50335, partition values: [2017,1,21]
20/06/06 19:25:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=31/000031_0, range: 0-52593, partition values: [2018,10,31]
20/06/06 19:25:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=21/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50335, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=31/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52593, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:01 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=4/000024_0, range: 0-50603, partition values: [2017,10,4]
20/06/06 19:26:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=4/000024_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50603, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:01 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=15/000040_0, range: 0-50333, partition values: [2018,12,15]
20/06/06 19:26:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=15/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50333, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=1/000038_0, range: 0-52588, partition values: [2018,5,1]
20/06/06 19:26:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=7/000034_0, range: 0-51524, partition values: [2020,2,7]
20/06/06 19:26:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=5/000027_0, range: 0-50595, partition values: [2019,12,5]
20/06/06 19:26:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=5/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50595, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=7/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51524, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=1/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52588, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=30/000036_0, range: 0-50333, partition values: [2019,12,30]
20/06/06 19:26:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=30/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50333, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=29/000039_0, range: 0-50593, partition values: [2017,7,29]
20/06/06 19:26:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=6/000031_0, range: 0-51518, partition values: [2020,2,6]
20/06/06 19:26:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=29/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50593, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=6/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51518, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=2/000041_0, range: 0-50332, partition values: [2018,6,2]
20/06/06 19:26:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=2/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50332, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=6/000037_0, range: 0-50592, partition values: [2018,8,6]
20/06/06 19:26:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=6/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50592, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=10/000031_0, range: 0-52586, partition values: [2017,9,10]
20/06/06 19:26:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=10/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52586, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=18/000027_0, range: 0-51515, partition values: [2017,1,18]
20/06/06 19:26:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=18/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 51515, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=11/000038_0, range: 0-50329, partition values: [2018,5,11]
20/06/06 19:26:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=11/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50329, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:16 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=20/000034_0, range: 0-51509, partition values: [2017,6,20]
20/06/06 19:26:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=20/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51509, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=18/000040_0, range: 0-52581, partition values: [2019,2,18]
20/06/06 19:26:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=18/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52581, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=7/000041_0, range: 0-50588, partition values: [2018,6,7]
20/06/06 19:26:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=7/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50588, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=1/000039_0, range: 0-51509, partition values: [2018,5,1]
20/06/06 19:26:20 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=1/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51509, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:20 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=4/000028_0, range: 0-50327, partition values: [2017,4,4]
20/06/06 19:26:22 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=4/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50327, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:22 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=16/000036_0, range: 0-52579, partition values: [2019,8,16]
20/06/06 19:26:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=12/000031_0, range: 0-50587, partition values: [2017,4,12]
20/06/06 19:26:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=16/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52579, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=12/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50587, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=24/000036_0, range: 0-50325, partition values: [2020,2,24]
20/06/06 19:26:25 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=24/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50325, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:25 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=24/000042_0, range: 0-52576, partition values: [2020,3,24]
20/06/06 19:26:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=24/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52576, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=24/000038_0, range: 0-50587, partition values: [2018,9,24]
20/06/06 19:26:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=24/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50587, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=24/000028_0, range: 0-51508, partition values: [2017,3,24]
20/06/06 19:26:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=24/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 51508, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=29/000032_0, range: 0-50324, partition values: [2019,11,29]
20/06/06 19:26:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=29/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50324, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=11/000028_0, range: 0-52573, partition values: [2017,5,11]
20/06/06 19:26:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=11/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 52573, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=2/000026_0, range: 0-51507, partition values: [2019,12,2]
20/06/06 19:26:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=2/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51507, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=24/000037_0, range: 0-50324, partition values: [2019,6,24]
20/06/06 19:26:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=25/000032_0, range: 0-50587, partition values: [2017,2,25]
20/06/06 19:26:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=24/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50324, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=25/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50587, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:34 INFO Executor: Finished task 1463.0 in stage 14.0 (TID 4281). 2549 bytes result sent to driver
20/06/06 19:26:34 INFO CoarseGrainedExecutorBackend: Got assigned task 4920
20/06/06 19:26:34 INFO Executor: Running task 2102.0 in stage 14.0 (TID 4920)
20/06/06 19:26:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=28/000049_0, range: 0-13298, partition values: [2018,1,28]
20/06/06 19:26:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=28/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13298, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=9/000032_0, range: 0-50584, partition values: [2017,11,9]
20/06/06 19:26:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=9/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50584, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=17/000037_0, range: 0-50324, partition values: [2020,2,17]
20/06/06 19:26:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=8/000037_0, range: 0-51507, partition values: [2019,8,8]
20/06/06 19:26:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=17/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50324, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=5/000044_0, range: 0-13298, partition values: [2017,9,5]
20/06/06 19:26:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=5/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13298, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=8/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 51507, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=31/000052_0, range: 0-13297, partition values: [2017,8,31]
20/06/06 19:26:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=31/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13297, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2015/month=11/day=4/005996_0, range: 0-13291, partition values: [2015,11,4]
20/06/06 19:26:39 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2015/month=11/day=4/005996_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 13291, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:39 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=30/005997_0, range: 0-13289, partition values: [2016,5,30]
20/06/06 19:26:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=30/005997_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 13289, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:40 INFO Executor: Finished task 1476.0 in stage 14.0 (TID 4294). 2549 bytes result sent to driver
20/06/06 19:26:40 INFO CoarseGrainedExecutorBackend: Got assigned task 4957
20/06/06 19:26:40 INFO Executor: Running task 2139.0 in stage 14.0 (TID 4957)
20/06/06 19:26:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=21/000050_0, range: 0-11302, partition values: [2017,7,21]
20/06/06 19:26:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=2/003707_0, range: 0-50322, partition values: [2016,5,2]
20/06/06 19:26:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=21/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11302, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=20/000052_0, range: 0-13284, partition values: [2019,12,20]
20/06/06 19:26:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=2/003707_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50322, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=20/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13284, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=1/000051_0, range: 0-11300, partition values: [2018,9,1]
20/06/06 19:26:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=1/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11300, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=22/000044_0, range: 0-13282, partition values: [2017,8,22]
20/06/06 19:26:42 INFO Executor: Finished task 1490.0 in stage 14.0 (TID 4308). 2549 bytes result sent to driver
20/06/06 19:26:42 INFO CoarseGrainedExecutorBackend: Got assigned task 4980
20/06/06 19:26:42 INFO Executor: Running task 2162.0 in stage 14.0 (TID 4980)
20/06/06 19:26:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=8/000051_0, range: 0-10435, partition values: [2018,6,8]
20/06/06 19:26:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=22/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13282, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=8/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10435, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=17/000036_0, range: 0-50580, partition values: [2018,6,17]
20/06/06 19:26:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=28/000053_0, range: 0-11300, partition values: [2018,3,28]
20/06/06 19:26:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=28/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11300, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=17/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50580, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=12/000054_0, range: 0-13280, partition values: [2019,1,12]
20/06/06 19:26:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=14/000046_0, range: 0-10435, partition values: [2019,3,14]
20/06/06 19:26:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=14/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10435, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=12/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13280, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=14/000048_0, range: 0-10433, partition values: [2019,2,14]
20/06/06 19:26:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=14/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10433, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=5/000042_0, range: 0-11297, partition values: [2017,2,5]
20/06/06 19:26:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=5/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 11297, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=30/000056_0, range: 0-11296, partition values: [2018,3,30]
20/06/06 19:26:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=30/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11296, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=25/000046_0, range: 0-13279, partition values: [2017,8,25]
20/06/06 19:26:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=25/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13279, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=26/000042_0, range: 0-10433, partition values: [2017,3,26]
20/06/06 19:26:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=26/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 10433, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=18/000053_0, range: 0-11292, partition values: [2017,12,18]
20/06/06 19:26:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=26/000049_0, range: 0-10433, partition values: [2017,10,26]
20/06/06 19:26:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=18/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11292, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=26/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10433, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=8/000047_0, range: 0-13277, partition values: [2020,1,8]
20/06/06 19:26:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=8/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13277, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=14/000029_0, range: 0-50575, partition values: [2017,3,14]
20/06/06 19:26:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=14/000029_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 50575, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=14/000049_0, range: 0-10432, partition values: [2018,8,14]
20/06/06 19:26:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=30/000048_0, range: 0-13273, partition values: [2018,8,30]
20/06/06 19:26:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=5/000051_0, range: 0-11291, partition values: [2017,6,5]
20/06/06 19:26:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=30/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13273, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=14/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10432, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=5/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11291, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=5/000050_0, range: 0-11290, partition values: [2017,7,5]
20/06/06 19:26:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=22/000050_0, range: 0-13269, partition values: [2018,2,22]
20/06/06 19:26:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=5/000049_0, range: 0-10432, partition values: [2018,8,5]
20/06/06 19:26:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=5/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11290, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=22/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13269, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=5/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10432, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=14/000050_0, range: 0-11287, partition values: [2018,7,14]
20/06/06 19:26:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=14/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11287, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=17/000035_0, range: 0-50570, partition values: [2018,4,17]
20/06/06 19:26:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=26/000043_0, range: 0-10429, partition values: [2017,3,26]
20/06/06 19:26:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=17/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50570, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=26/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 10429, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=17/000050_0, range: 0-11286, partition values: [2018,7,17]
20/06/06 19:26:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=6/000051_0, range: 0-10428, partition values: [2017,10,6]
20/06/06 19:26:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=17/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11286, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=18/000048_0, range: 0-13268, partition values: [2019,11,18]
20/06/06 19:26:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=6/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10428, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=18/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13268, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=12/000049_0, range: 0-11286, partition values: [2018,9,12]
20/06/06 19:26:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=12/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11286, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=20/000047_0, range: 0-13251, partition values: [2019,11,20]
20/06/06 19:26:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=20/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13251, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=11/000051_0, range: 0-10428, partition values: [2019,6,11]
20/06/06 19:26:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=11/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10428, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=28/000050_0, range: 0-11285, partition values: [2017,10,28]
20/06/06 19:26:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=26/000050_0, range: 0-10428, partition values: [2019,4,26]
20/06/06 19:26:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=28/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11285, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=25/000054_0, range: 0-13251, partition values: [2018,8,25]
20/06/06 19:26:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=26/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10428, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=25/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13251, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=30/000052_0, range: 0-10426, partition values: [2017,6,30]
20/06/06 19:26:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=30/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10426, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=5/000053_0, range: 0-11284, partition values: [2018,11,5]
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=29/000053_0, range: 0-13250, partition values: [2018,9,29]
20/06/06 19:26:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=5/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11284, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=20/000052_0, range: 0-10426, partition values: [2017,12,20]
20/06/06 19:26:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=29/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13250, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=20/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10426, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=19/000033_0, range: 0-50569, partition values: [2018,6,19]
20/06/06 19:26:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=30/000046_0, range: 0-11283, partition values: [2017,5,30]
20/06/06 19:26:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=30/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11283, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=19/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50569, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=11/000046_0, range: 0-13244, partition values: [2019,9,11]
20/06/06 19:26:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=11/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13244, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=29/000054_0, range: 0-11282, partition values: [2017,7,29]
20/06/06 19:26:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=30/000052_0, range: 0-10424, partition values: [2019,5,30]
20/06/06 19:26:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=29/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11282, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=30/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10424, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=23/000048_0, range: 0-11282, partition values: [2017,4,23]
20/06/06 19:26:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=22/000050_0, range: 0-13242, partition values: [2018,10,22]
20/06/06 19:26:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=11/000050_0, range: 0-10424, partition values: [2017,3,11]
20/06/06 19:26:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=23/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11282, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=22/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13242, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=11/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 10424, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=15/000040_0, range: 0-11281, partition values: [2017,2,15]
20/06/06 19:26:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000051_0, range: 0-10423, partition values: [2018,12,11]
20/06/06 19:26:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=15/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 11281, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10423, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=15/000048_0, range: 0-11280, partition values: [2017,9,15]
20/06/06 19:26:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=15/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11280, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=24/000048_0, range: 0-13241, partition values: [2018,12,24]
20/06/06 19:26:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=16/000052_0, range: 0-10422, partition values: [2018,7,16]
20/06/06 19:26:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=24/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13241, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=16/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10422, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:00 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=31/000044_0, range: 0-11280, partition values: [2017,3,31]
20/06/06 19:27:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=31/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 11280, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:01 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=14/000049_0, range: 0-10421, partition values: [2019,2,14]
20/06/06 19:27:01 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=28/000051_0, range: 0-11277, partition values: [2018,1,28]
20/06/06 19:27:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=14/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10421, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=28/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11277, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=11/000052_0, range: 0-13240, partition values: [2020,5,11]
20/06/06 19:27:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=11/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13240, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=7/000054_0, range: 0-10421, partition values: [2019,6,7]
20/06/06 19:27:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=7/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10421, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=11/000039_0, range: 0-50565, partition values: [2018,11,11]
20/06/06 19:27:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=23/000046_0, range: 0-11276, partition values: [2019,4,23]
20/06/06 19:27:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=11/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 50565, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=23/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11276, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=15/000053_0, range: 0-13239, partition values: [2019,5,15]
20/06/06 19:27:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=10/000048_0, range: 0-10420, partition values: [2018,9,10]
20/06/06 19:27:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=10/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10420, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=15/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13239, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=29/000050_0, range: 0-11275, partition values: [2019,9,29]
20/06/06 19:27:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000052_0, range: 0-13239, partition values: [2019,1,30]
20/06/06 19:27:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=29/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11275, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13239, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=8/000052_0, range: 0-10420, partition values: [2019,6,8]
20/06/06 19:27:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=4/000053_0, range: 0-11271, partition values: [2018,11,4]
20/06/06 19:27:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=8/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10420, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=4/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11271, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:05 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=5/000050_0, range: 0-10419, partition values: [2017,5,5]
20/06/06 19:27:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=5/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10419, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=2/000048_0, range: 0-11270, partition values: [2018,11,2]
20/06/06 19:27:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=4/000047_0, range: 0-13235, partition values: [2019,3,4]
20/06/06 19:27:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=26/000041_0, range: 0-10417, partition values: [2017,1,26]
20/06/06 19:27:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=2/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11270, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=4/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13235, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=26/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 10417, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=18/000050_0, range: 0-10416, partition values: [2017,2,18]
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=18/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 10416, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=9/000052_0, range: 0-11270, partition values: [2017,8,9]
20/06/06 19:27:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=15/000045_0, range: 0-13235, partition values: [2017,9,15]
20/06/06 19:27:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=17/000051_0, range: 0-10414, partition values: [2019,6,17]
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=9/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11270, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=15/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13235, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=17/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10414, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=27/000052_0, range: 0-11270, partition values: [2017,11,27]
20/06/06 19:27:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=16/000043_0, range: 0-10410, partition values: [2017,4,16]
20/06/06 19:27:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=27/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11270, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=16/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10410, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=15/000050_0, range: 0-13231, partition values: [2018,5,15]
20/06/06 19:27:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=15/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13231, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=22/000051_0, range: 0-10410, partition values: [2017,12,22]
20/06/06 19:27:09 INFO Executor: Finished task 1487.0 in stage 14.0 (TID 4305). 2592 bytes result sent to driver
20/06/06 19:27:09 INFO CoarseGrainedExecutorBackend: Got assigned task 5142
20/06/06 19:27:09 INFO Executor: Running task 2324.0 in stage 14.0 (TID 5142)
20/06/06 19:27:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=12/000056_0, range: 0-6108, partition values: [2020,3,12]
20/06/06 19:27:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=22/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10410, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=12/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6108, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=7/000052_0, range: 0-6107, partition values: [2017,12,7]
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=3/000049_0, range: 0-11267, partition values: [2018,10,3]
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=7/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6107, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=3/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11267, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=6/000044_0, range: 0-13229, partition values: [2019,11,6]
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=14/000047_0, range: 0-10407, partition values: [2017,5,14]
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=6/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13229, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=14/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10407, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=29/000059_0, range: 0-6106, partition values: [2018,5,29]
20/06/06 19:27:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=29/000059_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6106, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=2/000055_0, range: 0-11266, partition values: [2017,8,2]
20/06/06 19:27:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=2/000055_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11266, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=28/000051_0, range: 0-10407, partition values: [2017,5,28]
20/06/06 19:27:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=28/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10407, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=20/000048_0, range: 0-13229, partition values: [2018,12,20]
20/06/06 19:27:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=30/000054_0, range: 0-6105, partition values: [2017,8,30]
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=8/day=30/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6105, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=9/000052_0, range: 0-11265, partition values: [2019,6,9]
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=20/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13229, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=9/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11265, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=26/000052_0, range: 0-10407, partition values: [2018,5,26]
20/06/06 19:27:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=9/000062_0, range: 0-6104, partition values: [2020,5,9]
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=26/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10407, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=28/000049_0, range: 0-11265, partition values: [2019,2,28]
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=9/000062_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6104, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=28/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11265, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=30/000056_0, range: 0-6104, partition values: [2018,7,30]
20/06/06 19:27:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000050_0, range: 0-13228, partition values: [2019,1,30]
20/06/06 19:27:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=30/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6104, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=20/000053_0, range: 0-10406, partition values: [2019,2,20]
20/06/06 19:27:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13228, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=20/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10406, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=19/000052_0, range: 0-11265, partition values: [2018,3,19]
20/06/06 19:27:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=19/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11265, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=29/000053_0, range: 0-6103, partition values: [2018,6,29]
20/06/06 19:27:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=29/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6103, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=16/000052_0, range: 0-10405, partition values: [2019,6,16]
20/06/06 19:27:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=19/000052_0, range: 0-6102, partition values: [2018,7,19]
20/06/06 19:27:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=16/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 10405, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=19/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6102, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=13/000052_0, range: 0-13227, partition values: [2018,5,13]
20/06/06 19:27:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=13/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13227, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:15 INFO Executor: Finished task 2162.0 in stage 14.0 (TID 4980). 2549 bytes result sent to driver
20/06/06 19:27:15 INFO CoarseGrainedExecutorBackend: Got assigned task 5300
20/06/06 19:27:15 INFO Executor: Running task 208.0 in stage 15.0 (TID 5300)
20/06/06 19:27:15 INFO TorrentBroadcast: Started reading broadcast variable 18
20/06/06 19:27:15 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.4 KB, free 9.2 GB)
20/06/06 19:27:15 INFO TorrentBroadcast: Reading broadcast variable 18 took 9 ms
20/06/06 19:27:15 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 25.4 KB, free 9.2 GB)
20/06/06 19:27:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=29/000053_0, range: 0-11264, partition values: [2018,5,29]
20/06/06 19:27:15 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/user_country_dim/000034_0:134217728+67108864
20/06/06 19:27:15 INFO TorrentBroadcast: Started reading broadcast variable 13
20/06/06 19:27:15 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-143.us-west-2.compute.internal/10.128.11.143:46083 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:15 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 38.9 KB, free 9.2 GB)
20/06/06 19:27:15 INFO TorrentBroadcast: Reading broadcast variable 13 took 22 ms
20/06/06 19:27:15 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 591.5 KB, free 9.2 GB)
20/06/06 19:27:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=29/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 11264, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:16 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=28/000051_0, range: 0-6101, partition values: [2018,8,28]
20/06/06 19:27:16 INFO GPLNativeCodeLoader: Loaded native gpl library
20/06/06 19:27:16 INFO LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev dd4c76892e34528885afc09320477261050f9ab5]
20/06/06 19:27:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=28/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6101, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:16 INFO CodeGenerator: Code generated in 11.93263 ms
20/06/06 19:27:16 INFO CodeGenerator: Code generated in 69.667431 ms
20/06/06 19:27:16 INFO CodeGenerator: Code generated in 7.770392 ms
20/06/06 19:27:16 INFO CodeGenerator: Code generated in 17.591862 ms
20/06/06 19:27:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=7/005998_0, range: 0-13226, partition values: [2016,5,7]
20/06/06 19:27:17 INFO Executor: Finished task 2139.0 in stage 14.0 (TID 4957). 2592 bytes result sent to driver
20/06/06 19:27:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=12/000056_0, range: 0-6101, partition values: [2018,11,12]
20/06/06 19:27:17 INFO CoarseGrainedExecutorBackend: Got assigned task 5368
20/06/06 19:27:17 INFO Executor: Running task 57.0 in stage 18.0 (TID 5368)
20/06/06 19:27:17 INFO TorrentBroadcast: Started reading broadcast variable 20
20/06/06 19:27:17 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-143.us-west-2.compute.internal/10.128.11.143:38813 after 6 ms (0 ms spent in bootstraps)
20/06/06 19:27:17 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 69.3 KB, free 9.2 GB)
20/06/06 19:27:17 INFO TorrentBroadcast: Reading broadcast variable 20 took 35 ms
20/06/06 19:27:17 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 437.1 KB, free 9.2 GB)
20/06/06 19:27:17 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=454/000000_0.gz:0+2168461
20/06/06 19:27:17 INFO TorrentBroadcast: Started reading broadcast variable 14
20/06/06 19:27:17 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 39.1 KB, free 9.2 GB)
20/06/06 19:27:17 INFO TorrentBroadcast: Reading broadcast variable 14 took 8 ms
20/06/06 19:27:17 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 591.5 KB, free 9.2 GB)
20/06/06 19:27:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=12/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6101, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=7/005998_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 13226, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:17 INFO ZlibFactory: Successfully loaded & initialized native-zlib library
20/06/06 19:27:17 INFO CodecPool: Got brand-new decompressor [.gz]
20/06/06 19:27:17 INFO CodeGenerator: Code generated in 9.011662 ms
20/06/06 19:27:17 INFO CodeGenerator: Code generated in 8.214706 ms
20/06/06 19:27:17 INFO CodeGenerator: Code generated in 11.630338 ms
20/06/06 19:27:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=13/000048_0, range: 0-13225, partition values: [2018,7,13]
20/06/06 19:27:18 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=16/000055_0, range: 0-6101, partition values: [2018,11,16]
20/06/06 19:27:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=13/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13225, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=16/000055_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6101, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:18 INFO Executor: Finished task 57.0 in stage 18.0 (TID 5368). 1924 bytes result sent to driver
20/06/06 19:27:18 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=15/000053_0, range: 0-6099, partition values: [2018,11,15]
20/06/06 19:27:18 INFO CoarseGrainedExecutorBackend: Got assigned task 5534
20/06/06 19:27:18 INFO Executor: Running task 223.0 in stage 18.0 (TID 5534)
20/06/06 19:27:18 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=99/000000_0.gz:0+1974733
20/06/06 19:27:19 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=15/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6099, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:19 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:19 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=20/000051_0, range: 0-6097, partition values: [2017,9,20]
20/06/06 19:27:19 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000051_0, range: 0-13224, partition values: [2019,1,30]
20/06/06 19:27:19 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=20/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6097, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:19 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:19 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 13224, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:19 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:20 INFO Executor: Finished task 223.0 in stage 18.0 (TID 5534). 1967 bytes result sent to driver
20/06/06 19:27:20 INFO CoarseGrainedExecutorBackend: Got assigned task 5822
20/06/06 19:27:20 INFO Executor: Running task 511.0 in stage 18.0 (TID 5822)
20/06/06 19:27:20 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=298/000000_0.gz:0+3029241
20/06/06 19:27:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=25/000055_0, range: 0-6097, partition values: [2019,11,25]
20/06/06 19:27:20 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=25/000055_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6097, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:20 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=2/006421_0, range: 0-6095, partition values: [2016,5,2]
20/06/06 19:27:21 INFO Executor: Finished task 208.0 in stage 15.0 (TID 5300). 2405 bytes result sent to driver
20/06/06 19:27:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=2/006421_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 6095, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:21 INFO Executor: Finished task 511.0 in stage 18.0 (TID 5822). 1924 bytes result sent to driver
20/06/06 19:27:21 INFO Executor: Finished task 2102.0 in stage 14.0 (TID 4920). 2549 bytes result sent to driver
20/06/06 19:27:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=13/000053_0, range: 0-6094, partition values: [2018,9,13]
20/06/06 19:27:22 INFO CoarseGrainedExecutorBackend: Got assigned task 6094
20/06/06 19:27:22 INFO Executor: Running task 89.0 in stage 16.0 (TID 6094)
20/06/06 19:27:22 INFO CoarseGrainedExecutorBackend: Got assigned task 6160
20/06/06 19:27:22 INFO Executor: Running task 155.0 in stage 16.0 (TID 6160)
20/06/06 19:27:22 INFO CoarseGrainedExecutorBackend: Got assigned task 6182
20/06/06 19:27:22 INFO Executor: Running task 177.0 in stage 16.0 (TID 6182)
20/06/06 19:27:22 INFO MapOutputTrackerWorker: Updating epoch to 15 and clearing cache
20/06/06 19:27:22 INFO TorrentBroadcast: Started reading broadcast variable 35
20/06/06 19:27:22 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 11.7 KB, free 9.4 GB)
20/06/06 19:27:22 INFO TorrentBroadcast: Reading broadcast variable 35 took 19 ms
20/06/06 19:27:22 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 24.3 KB, free 9.4 GB)
20/06/06 19:27:22 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 14, fetching them
20/06/06 19:27:22 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 14, fetching them
20/06/06 19:27:22 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 14, fetching them
20/06/06 19:27:22 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:27:22 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:27:22 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=13/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6094, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:22 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:22 INFO ShuffleBlockFetcherIterator: Getting 219 non-empty blocks including 1 local blocks and 218 remote blocks
20/06/06 19:27:22 INFO ShuffleBlockFetcherIterator: Getting 219 non-empty blocks including 1 local blocks and 218 remote blocks
20/06/06 19:27:22 INFO ShuffleBlockFetcherIterator: Getting 219 non-empty blocks including 1 local blocks and 218 remote blocks
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-143.us-west-2.compute.internal/10.128.11.143:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-57.us-west-2.compute.internal/10.128.11.57:7337 after 4 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-202.us-west-2.compute.internal/10.128.11.202:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-205.us-west-2.compute.internal/10.128.11.205:7337 after 7 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-42.us-west-2.compute.internal/10.128.11.42:7337 after 9 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-148.us-west-2.compute.internal/10.128.11.148:7337 after 9 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-72.us-west-2.compute.internal/10.128.11.72:7337 after 2 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-90.us-west-2.compute.internal/10.128.11.90:7337 after 12 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-14.us-west-2.compute.internal/10.128.11.14:7337 after 20 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-88.us-west-2.compute.internal/10.128.11.88:7337 after 6 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:7337 after 15 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-83.us-west-2.compute.internal/10.128.11.83:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-200.us-west-2.compute.internal/10.128.11.200:7337 after 4 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-23.us-west-2.compute.internal/10.128.11.23:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-193.us-west-2.compute.internal/10.128.11.193:7337 after 13 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-37.us-west-2.compute.internal/10.128.11.37:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-157.us-west-2.compute.internal/10.128.11.157:7337 after 7 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-179.us-west-2.compute.internal/10.128.11.179:7337 after 5 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-131.us-west-2.compute.internal/10.128.11.131:7337 after 4 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-145.us-west-2.compute.internal/10.128.11.145:7337 after 4 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-225.us-west-2.compute.internal/10.128.11.225:7337 after 8 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-52.us-west-2.compute.internal/10.128.11.52:7337 after 9 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-137.us-west-2.compute.internal/10.128.11.137:7337 after 5 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-149.us-west-2.compute.internal/10.128.11.149:7337 after 41 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-100.us-west-2.compute.internal/10.128.11.100:7337 after 45 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-76.us-west-2.compute.internal/10.128.11.76:7337 after 30 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:7337 after 6 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-198.us-west-2.compute.internal/10.128.11.198:7337 after 37 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-129.us-west-2.compute.internal/10.128.11.129:7337 after 22 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-98.us-west-2.compute.internal/10.128.11.98:7337 after 7 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-156.us-west-2.compute.internal/10.128.11.156:7337 after 68 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-154.us-west-2.compute.internal/10.128.11.154:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-210.us-west-2.compute.internal/10.128.11.210:7337 after 23 ms (0 ms spent in bootstraps)
20/06/06 19:27:22 INFO ShuffleBlockFetcherIterator: Started 109 remote fetches in 327 ms
20/06/06 19:27:22 INFO ShuffleBlockFetcherIterator: Started 109 remote fetches in 343 ms
20/06/06 19:27:22 INFO ShuffleBlockFetcherIterator: Started 109 remote fetches in 344 ms
20/06/06 19:27:22 INFO CodeGenerator: Code generated in 80.99443 ms
20/06/06 19:27:22 INFO CodeGenerator: Code generated in 23.780603 ms
20/06/06 19:27:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=15/000057_0, range: 0-6092, partition values: [2017,10,15]
20/06/06 19:27:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=15/000057_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6092, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=16/000056_0, range: 0-6089, partition values: [2018,9,16]
20/06/06 19:27:24 INFO Executor: Finished task 177.0 in stage 16.0 (TID 6182). 3277 bytes result sent to driver
20/06/06 19:27:24 INFO CoarseGrainedExecutorBackend: Got assigned task 6331
20/06/06 19:27:24 INFO Executor: Running task 326.0 in stage 16.0 (TID 6331)
20/06/06 19:27:24 INFO ShuffleBlockFetcherIterator: Getting 219 non-empty blocks including 1 local blocks and 218 remote blocks
20/06/06 19:27:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=16/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6089, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:24 INFO ShuffleBlockFetcherIterator: Started 109 remote fetches in 76 ms
20/06/06 19:27:24 INFO Executor: Finished task 89.0 in stage 16.0 (TID 6094). 3277 bytes result sent to driver
20/06/06 19:27:24 INFO CoarseGrainedExecutorBackend: Got assigned task 6367
20/06/06 19:27:24 INFO Executor: Running task 362.0 in stage 16.0 (TID 6367)
20/06/06 19:27:24 INFO ShuffleBlockFetcherIterator: Getting 219 non-empty blocks including 1 local blocks and 218 remote blocks
20/06/06 19:27:24 INFO Executor: Finished task 155.0 in stage 16.0 (TID 6160). 3277 bytes result sent to driver
20/06/06 19:27:24 INFO CoarseGrainedExecutorBackend: Got assigned task 6373
20/06/06 19:27:24 INFO Executor: Running task 368.0 in stage 16.0 (TID 6373)
20/06/06 19:27:24 INFO ShuffleBlockFetcherIterator: Getting 219 non-empty blocks including 1 local blocks and 218 remote blocks
20/06/06 19:27:24 INFO ShuffleBlockFetcherIterator: Started 109 remote fetches in 46 ms
20/06/06 19:27:24 INFO ShuffleBlockFetcherIterator: Started 109 remote fetches in 56 ms
20/06/06 19:27:25 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=5/000050_0, range: 0-6089, partition values: [2018,8,5]
20/06/06 19:27:25 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=5/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6089, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:25 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:25 INFO Executor: Finished task 326.0 in stage 16.0 (TID 6331). 3320 bytes result sent to driver
20/06/06 19:27:25 INFO Executor: Finished task 368.0 in stage 16.0 (TID 6373). 3277 bytes result sent to driver
20/06/06 19:27:25 INFO Executor: Finished task 362.0 in stage 16.0 (TID 6367). 3277 bytes result sent to driver
20/06/06 19:27:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=26/000054_0, range: 0-6087, partition values: [2018,9,26]
20/06/06 19:27:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=26/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6087, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=20/000053_0, range: 0-6079, partition values: [2018,8,20]
20/06/06 19:27:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=20/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6079, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=15/000052_0, range: 0-6079, partition values: [2018,6,15]
20/06/06 19:27:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=15/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6079, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=7/000054_0, range: 0-6077, partition values: [2017,10,7]
20/06/06 19:27:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=7/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6077, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=16/000052_0, range: 0-6076, partition values: [2018,8,16]
20/06/06 19:27:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=16/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6076, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=28/000056_0, range: 0-6074, partition values: [2020,4,28]
20/06/06 19:27:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=28/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6074, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000054_0, range: 0-6073, partition values: [2018,12,11]
20/06/06 19:27:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=11/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6073, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=13/000052_0, range: 0-6073, partition values: [2018,11,13]
20/06/06 19:27:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=13/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6073, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:33 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=13/000049_0, range: 0-6072, partition values: [2018,6,13]
20/06/06 19:27:33 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=13/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6072, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:33 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:33 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=10/000050_0, range: 0-6072, partition values: [2019,10,10]
20/06/06 19:27:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=10/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6072, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=24/000056_0, range: 0-6071, partition values: [2019,2,24]
20/06/06 19:27:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=24/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6071, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=13/000054_0, range: 0-6071, partition values: [2017,9,13]
20/06/06 19:27:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=13/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6071, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=17/000054_0, range: 0-6070, partition values: [2018,6,17]
20/06/06 19:27:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=17/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 6070, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:36 INFO Executor: Finished task 2324.0 in stage 14.0 (TID 5142). 2549 bytes result sent to driver
20/06/06 19:28:37 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/06/06 19:28:37 INFO DiskBlockManager: Shutdown hook called
20/06/06 19:28:37 INFO ShutdownHookManager: Shutdown hook called
