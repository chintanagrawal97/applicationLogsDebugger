SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/mnt/yarn/usercache/hadoop/filecache/10/__spark_libs__8474873730201561419.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/06/06 19:02:39 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 9987@ip-10-128-11-54
20/06/06 19:02:39 INFO SignalUtils: Registered signal handler for TERM
20/06/06 19:02:39 INFO SignalUtils: Registered signal handler for HUP
20/06/06 19:02:39 INFO SignalUtils: Registered signal handler for INT
20/06/06 19:02:40 INFO SecurityManager: Changing view acls to: yarn,hadoop
20/06/06 19:02:40 INFO SecurityManager: Changing modify acls to: yarn,hadoop
20/06/06 19:02:40 INFO SecurityManager: Changing view acls groups to: 
20/06/06 19:02:40 INFO SecurityManager: Changing modify acls groups to: 
20/06/06 19:02:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
20/06/06 19:02:40 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:42673 after 82 ms (0 ms spent in bootstraps)
20/06/06 19:02:40 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
20/06/06 19:02:40 INFO SecurityManager: Changing view acls to: yarn,hadoop
20/06/06 19:02:40 INFO SecurityManager: Changing modify acls to: yarn,hadoop
20/06/06 19:02:40 INFO SecurityManager: Changing view acls groups to: 
20/06/06 19:02:40 INFO SecurityManager: Changing modify acls groups to: 
20/06/06 19:02:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
20/06/06 19:02:40 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:42673 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:02:40 INFO DiskBlockManager: Created local directory at /mnt/yarn/usercache/hadoop/appcache/application_1591494778265_0001/blockmgr-0950eb76-7901-41a3-afd2-3c867b3c2594
20/06/06 19:02:40 INFO MemoryStore: MemoryStore started with capacity 9.4 GB
20/06/06 19:02:41 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@ip-10-128-11-116.us-west-2.compute.internal:42673
20/06/06 19:02:41 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/06/06 19:02:41 INFO Executor: Starting executor ID 17 on host ip-10-128-11-54.us-west-2.compute.internal
20/06/06 19:02:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36753.
20/06/06 19:02:41 INFO NettyBlockTransferService: Server created on ip-10-128-11-54.us-west-2.compute.internal:36753
20/06/06 19:02:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/06/06 19:02:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(17, ip-10-128-11-54.us-west-2.compute.internal, 36753, None)
20/06/06 19:02:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(17, ip-10-128-11-54.us-west-2.compute.internal, 36753, None)
20/06/06 19:02:41 INFO BlockManager: external shuffle service port = 7337
20/06/06 19:02:41 INFO BlockManager: Registering executor with local external shuffle service.
20/06/06 19:02:41 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:7337 after 0 ms (0 ms spent in bootstraps)
20/06/06 19:02:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(17, ip-10-128-11-54.us-west-2.compute.internal, 36753, None)
20/06/06 19:03:18 INFO CoarseGrainedExecutorBackend: Got assigned task 39
20/06/06 19:03:18 INFO CoarseGrainedExecutorBackend: Got assigned task 80
20/06/06 19:03:18 INFO CoarseGrainedExecutorBackend: Got assigned task 121
20/06/06 19:03:18 INFO CoarseGrainedExecutorBackend: Got assigned task 162
20/06/06 19:03:18 INFO Executor: Running task 39.0 in stage 0.0 (TID 39)
20/06/06 19:03:18 INFO Executor: Running task 80.0 in stage 0.0 (TID 80)
20/06/06 19:03:18 INFO Executor: Running task 121.0 in stage 0.0 (TID 121)
20/06/06 19:03:18 INFO Executor: Running task 162.0 in stage 0.0 (TID 162)
20/06/06 19:03:18 INFO TorrentBroadcast: Started reading broadcast variable 0
20/06/06 19:03:19 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:36317 after 3 ms (0 ms spent in bootstraps)
20/06/06 19:03:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 40.2 KB, free 9.4 GB)
20/06/06 19:03:19 INFO TorrentBroadcast: Reading broadcast variable 0 took 185 ms
20/06/06 19:03:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 131.9 KB, free 9.4 GB)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt1/s3
java.nio.file.AccessDeniedException: /mnt1
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt2/s3
java.nio.file.AccessDeniedException: /mnt2
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt3/s3
java.nio.file.AccessDeniedException: /mnt3
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt4/s3
java.nio.file.AccessDeniedException: /mnt4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt5/s3
java.nio.file.AccessDeniedException: /mnt5
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt6/s3
java.nio.file.AccessDeniedException: /mnt6
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt7/s3
java.nio.file.AccessDeniedException: /mnt7
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt8/s3
java.nio.file.AccessDeniedException: /mnt8
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt9/s3
java.nio.file.AccessDeniedException: /mnt9
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt10/s3
java.nio.file.AccessDeniedException: /mnt10
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:22 WARN ConfigurationUtils: Cannot create temp dir with proper permission: /mnt11/s3
java.nio.file.AccessDeniedException: /mnt11
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
	at java.nio.file.Files.createDirectories(Files.java:767)
	at com.amazon.ws.emr.hadoop.fs.util.ConfigurationUtils.getTestedTempPaths(ConfigurationUtils.java:258)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.<init>(ConsistencyCheckerS3FileSystem.java:160)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.createConsistencyCheckerFileSystem(S3NativeFileSystem2.java:405)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.initialize(S3NativeFileSystem2.java:89)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:112)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2859)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:272)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/06/06 19:03:23 INFO Executor: Finished task 121.0 in stage 0.0 (TID 121). 4956 bytes result sent to driver
20/06/06 19:03:23 INFO Executor: Finished task 39.0 in stage 0.0 (TID 39). 5418 bytes result sent to driver
20/06/06 19:03:23 INFO CoarseGrainedExecutorBackend: Got assigned task 236
20/06/06 19:03:23 INFO Executor: Finished task 80.0 in stage 0.0 (TID 80). 14967 bytes result sent to driver
20/06/06 19:03:23 INFO Executor: Running task 236.0 in stage 0.0 (TID 236)
20/06/06 19:03:23 INFO Executor: Finished task 162.0 in stage 0.0 (TID 162). 13285 bytes result sent to driver
20/06/06 19:03:23 INFO CoarseGrainedExecutorBackend: Got assigned task 237
20/06/06 19:03:23 INFO CoarseGrainedExecutorBackend: Got assigned task 239
20/06/06 19:03:23 INFO Executor: Running task 237.0 in stage 0.0 (TID 237)
20/06/06 19:03:23 INFO Executor: Running task 239.0 in stage 0.0 (TID 239)
20/06/06 19:03:23 INFO CoarseGrainedExecutorBackend: Got assigned task 248
20/06/06 19:03:23 INFO Executor: Running task 248.0 in stage 0.0 (TID 248)
20/06/06 19:03:24 INFO Executor: Finished task 236.0 in stage 0.0 (TID 236). 4722 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 378
20/06/06 19:03:24 INFO Executor: Running task 378.0 in stage 0.0 (TID 378)
20/06/06 19:03:24 INFO Executor: Finished task 248.0 in stage 0.0 (TID 248). 5099 bytes result sent to driver
20/06/06 19:03:24 INFO Executor: Finished task 237.0 in stage 0.0 (TID 237). 5764 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 385
20/06/06 19:03:24 INFO Executor: Running task 385.0 in stage 0.0 (TID 385)
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 386
20/06/06 19:03:24 INFO Executor: Running task 386.0 in stage 0.0 (TID 386)
20/06/06 19:03:24 INFO Executor: Finished task 239.0 in stage 0.0 (TID 239). 13407 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 417
20/06/06 19:03:24 INFO Executor: Running task 417.0 in stage 0.0 (TID 417)
20/06/06 19:03:24 INFO Executor: Finished task 378.0 in stage 0.0 (TID 378). 12279 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 432
20/06/06 19:03:24 INFO Executor: Running task 432.0 in stage 0.0 (TID 432)
20/06/06 19:03:24 INFO Executor: Finished task 385.0 in stage 0.0 (TID 385). 13407 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 460
20/06/06 19:03:24 INFO Executor: Running task 460.0 in stage 0.0 (TID 460)
20/06/06 19:03:24 INFO Executor: Finished task 386.0 in stage 0.0 (TID 386). 13580 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 492
20/06/06 19:03:24 INFO Executor: Running task 492.0 in stage 0.0 (TID 492)
20/06/06 19:03:24 INFO Executor: Finished task 417.0 in stage 0.0 (TID 417). 13679 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 514
20/06/06 19:03:24 INFO Executor: Running task 514.0 in stage 0.0 (TID 514)
20/06/06 19:03:24 INFO Executor: Finished task 432.0 in stage 0.0 (TID 432). 12754 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 537
20/06/06 19:03:24 INFO Executor: Finished task 460.0 in stage 0.0 (TID 460). 14647 bytes result sent to driver
20/06/06 19:03:24 INFO Executor: Running task 537.0 in stage 0.0 (TID 537)
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 551
20/06/06 19:03:24 INFO Executor: Running task 551.0 in stage 0.0 (TID 551)
20/06/06 19:03:24 INFO Executor: Finished task 514.0 in stage 0.0 (TID 514). 5591 bytes result sent to driver
20/06/06 19:03:24 INFO Executor: Finished task 492.0 in stage 0.0 (TID 492). 13623 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 593
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 594
20/06/06 19:03:24 INFO Executor: Running task 594.0 in stage 0.0 (TID 594)
20/06/06 19:03:24 INFO Executor: Running task 593.0 in stage 0.0 (TID 593)
20/06/06 19:03:24 INFO Executor: Finished task 537.0 in stage 0.0 (TID 537). 13364 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 624
20/06/06 19:03:24 INFO Executor: Running task 624.0 in stage 0.0 (TID 624)
20/06/06 19:03:24 INFO Executor: Finished task 551.0 in stage 0.0 (TID 551). 14389 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 648
20/06/06 19:03:24 INFO Executor: Running task 648.0 in stage 0.0 (TID 648)
20/06/06 19:03:24 INFO Executor: Finished task 593.0 in stage 0.0 (TID 593). 5784 bytes result sent to driver
20/06/06 19:03:24 INFO Executor: Finished task 624.0 in stage 0.0 (TID 624). 15142 bytes result sent to driver
20/06/06 19:03:24 INFO Executor: Finished task 594.0 in stage 0.0 (TID 594). 6179 bytes result sent to driver
20/06/06 19:03:24 INFO CoarseGrainedExecutorBackend: Got assigned task 706
20/06/06 19:03:24 INFO Executor: Running task 706.0 in stage 0.0 (TID 706)
20/06/06 19:03:24 INFO Executor: Finished task 648.0 in stage 0.0 (TID 648). 14292 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 748
20/06/06 19:03:25 INFO Executor: Running task 748.0 in stage 0.0 (TID 748)
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 749
20/06/06 19:03:25 INFO Executor: Running task 749.0 in stage 0.0 (TID 749)
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 790
20/06/06 19:03:25 INFO Executor: Running task 790.0 in stage 0.0 (TID 790)
20/06/06 19:03:25 INFO Executor: Finished task 706.0 in stage 0.0 (TID 706). 14012 bytes result sent to driver
20/06/06 19:03:25 INFO Executor: Finished task 748.0 in stage 0.0 (TID 748). 14986 bytes result sent to driver
20/06/06 19:03:25 INFO Executor: Finished task 749.0 in stage 0.0 (TID 749). 14230 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 853
20/06/06 19:03:25 INFO Executor: Running task 853.0 in stage 0.0 (TID 853)
20/06/06 19:03:25 INFO Executor: Finished task 790.0 in stage 0.0 (TID 790). 14492 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 883
20/06/06 19:03:25 INFO Executor: Running task 883.0 in stage 0.0 (TID 883)
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 885
20/06/06 19:03:25 INFO Executor: Running task 885.0 in stage 0.0 (TID 885)
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 918
20/06/06 19:03:25 INFO Executor: Running task 918.0 in stage 0.0 (TID 918)
20/06/06 19:03:25 INFO Executor: Finished task 853.0 in stage 0.0 (TID 853). 6003 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 980
20/06/06 19:03:25 INFO Executor: Running task 980.0 in stage 0.0 (TID 980)
20/06/06 19:03:25 INFO Executor: Finished task 883.0 in stage 0.0 (TID 883). 11794 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1009
20/06/06 19:03:25 INFO Executor: Running task 1009.0 in stage 0.0 (TID 1009)
20/06/06 19:03:25 INFO Executor: Finished task 885.0 in stage 0.0 (TID 885). 12711 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1053
20/06/06 19:03:25 INFO Executor: Running task 1053.0 in stage 0.0 (TID 1053)
20/06/06 19:03:25 INFO Executor: Finished task 918.0 in stage 0.0 (TID 918). 5529 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1093
20/06/06 19:03:25 INFO Executor: Running task 1093.0 in stage 0.0 (TID 1093)
20/06/06 19:03:25 INFO Executor: Finished task 1009.0 in stage 0.0 (TID 1009). 14647 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1123
20/06/06 19:03:25 INFO Executor: Running task 1123.0 in stage 0.0 (TID 1123)
20/06/06 19:03:25 INFO Executor: Finished task 1053.0 in stage 0.0 (TID 1053). 13623 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1133
20/06/06 19:03:25 INFO Executor: Running task 1133.0 in stage 0.0 (TID 1133)
20/06/06 19:03:25 INFO Executor: Finished task 980.0 in stage 0.0 (TID 980). 14449 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1142
20/06/06 19:03:25 INFO Executor: Running task 1142.0 in stage 0.0 (TID 1142)
20/06/06 19:03:25 INFO Executor: Finished task 1133.0 in stage 0.0 (TID 1133). 5116 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1202
20/06/06 19:03:25 INFO Executor: Running task 1202.0 in stage 0.0 (TID 1202)
20/06/06 19:03:25 INFO Executor: Finished task 1093.0 in stage 0.0 (TID 1093). 14230 bytes result sent to driver
20/06/06 19:03:25 INFO Executor: Finished task 1123.0 in stage 0.0 (TID 1123). 14055 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1228
20/06/06 19:03:25 INFO Executor: Running task 1228.0 in stage 0.0 (TID 1228)
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1231
20/06/06 19:03:25 INFO Executor: Running task 1231.0 in stage 0.0 (TID 1231)
20/06/06 19:03:25 INFO Executor: Finished task 1142.0 in stage 0.0 (TID 1142). 12970 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1273
20/06/06 19:03:25 INFO Executor: Running task 1273.0 in stage 0.0 (TID 1273)
20/06/06 19:03:25 INFO Executor: Finished task 1202.0 in stage 0.0 (TID 1202). 14230 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1337
20/06/06 19:03:25 INFO Executor: Running task 1337.0 in stage 0.0 (TID 1337)
20/06/06 19:03:25 INFO Executor: Finished task 1231.0 in stage 0.0 (TID 1231). 14665 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1342
20/06/06 19:03:25 INFO Executor: Running task 1342.0 in stage 0.0 (TID 1342)
20/06/06 19:03:25 INFO Executor: Finished task 1228.0 in stage 0.0 (TID 1228). 12917 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1356
20/06/06 19:03:25 INFO Executor: Running task 1356.0 in stage 0.0 (TID 1356)
20/06/06 19:03:25 INFO Executor: Finished task 1342.0 in stage 0.0 (TID 1342). 14708 bytes result sent to driver
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1452
20/06/06 19:03:25 INFO Executor: Finished task 1273.0 in stage 0.0 (TID 1273). 13796 bytes result sent to driver
20/06/06 19:03:25 INFO Executor: Running task 1452.0 in stage 0.0 (TID 1452)
20/06/06 19:03:25 INFO CoarseGrainedExecutorBackend: Got assigned task 1457
20/06/06 19:03:25 INFO Executor: Running task 1457.0 in stage 0.0 (TID 1457)
20/06/06 19:03:26 INFO Executor: Finished task 1337.0 in stage 0.0 (TID 1337). 14230 bytes result sent to driver
20/06/06 19:03:26 INFO CoarseGrainedExecutorBackend: Got assigned task 1471
20/06/06 19:03:26 INFO Executor: Running task 1471.0 in stage 0.0 (TID 1471)
20/06/06 19:03:26 INFO Executor: Finished task 1356.0 in stage 0.0 (TID 1356). 13796 bytes result sent to driver
20/06/06 19:03:26 INFO CoarseGrainedExecutorBackend: Got assigned task 1524
20/06/06 19:03:26 INFO Executor: Running task 1524.0 in stage 0.0 (TID 1524)
20/06/06 19:03:26 INFO Executor: Finished task 1452.0 in stage 0.0 (TID 1452). 13623 bytes result sent to driver
20/06/06 19:03:26 INFO CoarseGrainedExecutorBackend: Got assigned task 1558
20/06/06 19:03:26 INFO Executor: Running task 1558.0 in stage 0.0 (TID 1558)
20/06/06 19:03:26 INFO Executor: Finished task 1457.0 in stage 0.0 (TID 1457). 5982 bytes result sent to driver
20/06/06 19:03:26 INFO Executor: Finished task 1471.0 in stage 0.0 (TID 1471). 13954 bytes result sent to driver
20/06/06 19:03:26 INFO Executor: Finished task 1524.0 in stage 0.0 (TID 1524). 14449 bytes result sent to driver
20/06/06 19:03:26 INFO CoarseGrainedExecutorBackend: Got assigned task 1620
20/06/06 19:03:26 INFO CoarseGrainedExecutorBackend: Got assigned task 1621
20/06/06 19:03:26 INFO Executor: Running task 1621.0 in stage 0.0 (TID 1621)
20/06/06 19:03:26 INFO Executor: Running task 1620.0 in stage 0.0 (TID 1620)
20/06/06 19:03:26 INFO Executor: Finished task 1558.0 in stage 0.0 (TID 1558). 14492 bytes result sent to driver
20/06/06 19:03:26 INFO Executor: Finished task 1621.0 in stage 0.0 (TID 1621). 14012 bytes result sent to driver
20/06/06 19:03:26 INFO Executor: Finished task 1620.0 in stage 0.0 (TID 1620). 14665 bytes result sent to driver
20/06/06 19:03:50 INFO CoarseGrainedExecutorBackend: Got assigned task 1676
20/06/06 19:03:50 INFO Executor: Running task 2.0 in stage 1.0 (TID 1676)
20/06/06 19:03:50 INFO CoarseGrainedExecutorBackend: Got assigned task 1717
20/06/06 19:03:50 INFO Executor: Running task 43.0 in stage 1.0 (TID 1717)
20/06/06 19:03:50 INFO TorrentBroadcast: Started reading broadcast variable 17
20/06/06 19:03:50 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.3 KB, free 9.4 GB)
20/06/06 19:03:50 INFO TorrentBroadcast: Reading broadcast variable 17 took 17 ms
20/06/06 19:03:50 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 12.1 KB, free 9.4 GB)
20/06/06 19:03:50 INFO CoarseGrainedExecutorBackend: Got assigned task 1754
20/06/06 19:03:50 INFO CoarseGrainedExecutorBackend: Got assigned task 1795
20/06/06 19:03:50 INFO Executor: Running task 33.0 in stage 15.0 (TID 1754)
20/06/06 19:03:50 INFO Executor: Running task 74.0 in stage 15.0 (TID 1795)
20/06/06 19:03:50 INFO TorrentBroadcast: Started reading broadcast variable 18
20/06/06 19:03:50 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.4 KB, free 9.4 GB)
20/06/06 19:03:50 INFO TorrentBroadcast: Reading broadcast variable 18 took 24 ms
20/06/06 19:03:50 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 25.4 KB, free 9.4 GB)
20/06/06 19:03:51 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/master/tables/logical_uri_mapping/AF002062.logical_uri_mapping.11.gz:0+266359122
20/06/06 19:03:51 INFO TorrentBroadcast: Started reading broadcast variable 16
20/06/06 19:03:51 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/master/tables/logical_uri_mapping/AF002062.logical_uri_mapping.6.gz:0+266362470
20/06/06 19:03:51 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:41309 after 48 ms (0 ms spent in bootstraps)
20/06/06 19:03:51 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/user_country_dim/000011_0:134217728+67108864
20/06/06 19:03:51 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/user_country_dim/000004_0:0+67108864
20/06/06 19:03:51 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 38.9 KB, free 9.4 GB)
20/06/06 19:03:51 INFO TorrentBroadcast: Reading broadcast variable 16 took 131 ms
20/06/06 19:03:51 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 591.5 KB, free 9.4 GB)
20/06/06 19:03:51 INFO TorrentBroadcast: Started reading broadcast variable 13
20/06/06 19:03:51 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:34485 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:03:51 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 38.9 KB, free 9.4 GB)
20/06/06 19:03:51 INFO TorrentBroadcast: Reading broadcast variable 13 took 30 ms
20/06/06 19:03:51 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 591.5 KB, free 9.4 GB)
20/06/06 19:03:52 INFO GPLNativeCodeLoader: Loaded native gpl library
20/06/06 19:03:52 INFO LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev dd4c76892e34528885afc09320477261050f9ab5]
20/06/06 19:03:52 INFO ZlibFactory: Successfully loaded & initialized native-zlib library
20/06/06 19:03:52 INFO CodecPool: Got brand-new decompressor [.gz]
20/06/06 19:03:52 INFO CodecPool: Got brand-new decompressor [.gz]
20/06/06 19:03:53 INFO CodeGenerator: Code generated in 247.730993 ms
20/06/06 19:03:53 INFO CodeGenerator: Code generated in 253.284607 ms
20/06/06 19:03:53 INFO CodeGenerator: Code generated in 39.545498 ms
20/06/06 19:03:53 INFO CodeGenerator: Code generated in 86.589332 ms
20/06/06 19:03:53 INFO CodeGenerator: Code generated in 14.994337 ms
20/06/06 19:03:53 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:03:53 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:03:53 INFO CodeGenerator: Code generated in 48.886797 ms
20/06/06 19:03:53 INFO CodeGenerator: Code generated in 19.776455 ms
20/06/06 19:04:02 INFO Executor: Finished task 74.0 in stage 15.0 (TID 1795). 2447 bytes result sent to driver
20/06/06 19:04:02 INFO CoarseGrainedExecutorBackend: Got assigned task 1879
20/06/06 19:04:02 INFO Executor: Running task 11.0 in stage 5.0 (TID 1879)
20/06/06 19:04:02 INFO Executor: Finished task 33.0 in stage 15.0 (TID 1754). 2404 bytes result sent to driver
20/06/06 19:04:02 INFO TorrentBroadcast: Started reading broadcast variable 27
20/06/06 19:04:02 INFO CoarseGrainedExecutorBackend: Got assigned task 1883
20/06/06 19:04:02 INFO Executor: Running task 15.0 in stage 5.0 (TID 1883)
20/06/06 19:04:02 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 9.0 KB, free 9.0 GB)
20/06/06 19:04:02 INFO TorrentBroadcast: Reading broadcast variable 27 took 47 ms
20/06/06 19:04:02 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 21.7 KB, free 9.0 GB)
20/06/06 19:04:02 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/master/tables/customers/AF002062.customers.22.gz:0+266365681
20/06/06 19:04:02 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/master/tables/customers/AF002062.customers.19.gz:0+266367551
20/06/06 19:04:02 INFO TorrentBroadcast: Started reading broadcast variable 1
20/06/06 19:04:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 39.6 KB, free 9.0 GB)
20/06/06 19:04:02 INFO TorrentBroadcast: Reading broadcast variable 1 took 52 ms
20/06/06 19:04:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 591.5 KB, free 9.0 GB)
20/06/06 19:04:02 INFO CodecPool: Got brand-new decompressor [.gz]
20/06/06 19:04:02 INFO CodecPool: Got brand-new decompressor [.gz]
20/06/06 19:04:02 INFO CodeGenerator: Code generated in 55.571327 ms
20/06/06 19:04:02 INFO CodeGenerator: Code generated in 101.81525 ms
20/06/06 19:04:02 INFO CodeGenerator: Code generated in 50.406887 ms
20/06/06 19:04:02 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:04:02 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:04:54 INFO Executor: Finished task 11.0 in stage 5.0 (TID 1879). 1904 bytes result sent to driver
20/06/06 19:04:54 INFO CoarseGrainedExecutorBackend: Got assigned task 2005
20/06/06 19:04:54 INFO Executor: Running task 36.0 in stage 7.0 (TID 2005)
20/06/06 19:04:54 INFO TorrentBroadcast: Started reading broadcast variable 29
20/06/06 19:04:54 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 6.3 KB, free 5.7 GB)
20/06/06 19:04:54 INFO TorrentBroadcast: Reading broadcast variable 29 took 31 ms
20/06/06 19:04:54 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 12.1 KB, free 5.7 GB)
20/06/06 19:04:54 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000010_0:67108864+67108864
20/06/06 19:04:54 INFO TorrentBroadcast: Started reading broadcast variable 3
20/06/06 19:04:54 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:46861 after 14 ms (0 ms spent in bootstraps)
20/06/06 19:04:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 38.8 KB, free 5.7 GB)
20/06/06 19:04:54 INFO TorrentBroadcast: Reading broadcast variable 3 took 147 ms
20/06/06 19:04:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 591.5 KB, free 5.7 GB)
20/06/06 19:04:55 INFO CodeGenerator: Code generated in 17.250653 ms
20/06/06 19:04:55 INFO CodeGenerator: Code generated in 90.819131 ms
20/06/06 19:04:57 INFO Executor: Finished task 15.0 in stage 5.0 (TID 1883). 1904 bytes result sent to driver
20/06/06 19:04:57 INFO CoarseGrainedExecutorBackend: Got assigned task 2031
20/06/06 19:04:57 INFO Executor: Running task 62.0 in stage 7.0 (TID 2031)
20/06/06 19:04:57 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000019_0:0+67108864
20/06/06 19:05:00 INFO Executor: Finished task 36.0 in stage 7.0 (TID 2005). 1966 bytes result sent to driver
20/06/06 19:05:00 INFO CoarseGrainedExecutorBackend: Got assigned task 2055
20/06/06 19:05:00 INFO Executor: Running task 86.0 in stage 7.0 (TID 2055)
20/06/06 19:05:00 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000027_0:0+67108864
20/06/06 19:05:00 INFO Executor: Finished task 43.0 in stage 1.0 (TID 1717). 1966 bytes result sent to driver
20/06/06 19:05:00 INFO CoarseGrainedExecutorBackend: Got assigned task 2065
20/06/06 19:05:00 INFO Executor: Running task 96.0 in stage 7.0 (TID 2065)
20/06/06 19:05:00 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000030_0:67108864+67108864
20/06/06 19:05:01 INFO Executor: Finished task 62.0 in stage 7.0 (TID 2031). 1966 bytes result sent to driver
20/06/06 19:05:01 INFO CoarseGrainedExecutorBackend: Got assigned task 2088
20/06/06 19:05:01 INFO Executor: Running task 119.0 in stage 7.0 (TID 2088)
20/06/06 19:05:01 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000038_0:0+67108864
20/06/06 19:05:05 INFO Executor: Finished task 86.0 in stage 7.0 (TID 2055). 1966 bytes result sent to driver
20/06/06 19:05:05 INFO CoarseGrainedExecutorBackend: Got assigned task 2129
20/06/06 19:05:05 INFO Executor: Running task 160.0 in stage 7.0 (TID 2129)
20/06/06 19:05:05 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000051_0:134217728+64694760
20/06/06 19:05:05 INFO Executor: Finished task 96.0 in stage 7.0 (TID 2065). 1966 bytes result sent to driver
20/06/06 19:05:05 INFO CoarseGrainedExecutorBackend: Got assigned task 2141
20/06/06 19:05:05 INFO Executor: Running task 172.0 in stage 7.0 (TID 2141)
20/06/06 19:05:05 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000055_0:134217728+55666305
20/06/06 19:05:06 INFO Executor: Finished task 119.0 in stage 7.0 (TID 2088). 1966 bytes result sent to driver
20/06/06 19:05:06 INFO CoarseGrainedExecutorBackend: Got assigned task 2164
20/06/06 19:05:06 INFO Executor: Running task 195.0 in stage 7.0 (TID 2164)
20/06/06 19:05:06 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000062_0:0+67108864
20/06/06 19:05:09 INFO Executor: Finished task 172.0 in stage 7.0 (TID 2141). 1966 bytes result sent to driver
20/06/06 19:05:09 INFO CoarseGrainedExecutorBackend: Got assigned task 2211
20/06/06 19:05:09 INFO Executor: Running task 242.0 in stage 7.0 (TID 2211)
20/06/06 19:05:09 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000074_0:201326592+25056349
20/06/06 19:05:09 INFO Executor: Finished task 160.0 in stage 7.0 (TID 2129). 1966 bytes result sent to driver
20/06/06 19:05:09 INFO CoarseGrainedExecutorBackend: Got assigned task 2222
20/06/06 19:05:09 INFO Executor: Running task 253.0 in stage 7.0 (TID 2222)
20/06/06 19:05:09 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/customers_reg_date_fill/000077_0:134217728+67108864
20/06/06 19:05:11 INFO Executor: Finished task 242.0 in stage 7.0 (TID 2211). 1923 bytes result sent to driver
20/06/06 19:05:11 INFO CoarseGrainedExecutorBackend: Got assigned task 2245
20/06/06 19:05:11 INFO Executor: Running task 5.0 in stage 9.0 (TID 2245)
20/06/06 19:05:11 INFO TorrentBroadcast: Started reading broadcast variable 22
20/06/06 19:05:11 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 11.2 KB, free 7.4 GB)
20/06/06 19:05:11 INFO TorrentBroadcast: Reading broadcast variable 22 took 31 ms
20/06/06 19:05:11 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 23.9 KB, free 7.4 GB)
20/06/06 19:05:11 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/customer/tables/customers_attribute_timers_log/AF002062.customers_attribute_timers_log.1.gz:0+24561126
20/06/06 19:05:11 INFO TorrentBroadcast: Started reading broadcast variable 9
20/06/06 19:05:11 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-42.us-west-2.compute.internal/10.128.11.42:42215 after 9 ms (0 ms spent in bootstraps)
20/06/06 19:05:11 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 39.0 KB, free 7.4 GB)
20/06/06 19:05:11 INFO TorrentBroadcast: Reading broadcast variable 9 took 119 ms
20/06/06 19:05:11 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 591.5 KB, free 7.4 GB)
20/06/06 19:05:11 INFO CodeGenerator: Code generated in 9.79706 ms
20/06/06 19:05:11 INFO CodeGenerator: Code generated in 145.026564 ms
20/06/06 19:05:11 INFO CodeGenerator: Code generated in 27.948763 ms
20/06/06 19:05:11 INFO CodeGenerator: Code generated in 173.354768 ms
20/06/06 19:05:11 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:05:12 INFO Executor: Finished task 195.0 in stage 7.0 (TID 2164). 1966 bytes result sent to driver
20/06/06 19:05:12 INFO CoarseGrainedExecutorBackend: Got assigned task 2263
20/06/06 19:05:12 INFO Executor: Running task 17.0 in stage 10.0 (TID 2263)
20/06/06 19:05:12 INFO TorrentBroadcast: Started reading broadcast variable 23
20/06/06 19:05:12 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:39105 after 42 ms (0 ms spent in bootstraps)
20/06/06 19:05:12 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.6 KB, free 7.5 GB)
20/06/06 19:05:12 INFO TorrentBroadcast: Reading broadcast variable 23 took 177 ms
20/06/06 19:05:12 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 22.0 KB, free 7.5 GB)
20/06/06 19:05:12 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/customer/tables/customers_preferences/AF001838.customers_preferences.10.gz:0+189378174
20/06/06 19:05:12 INFO TorrentBroadcast: Started reading broadcast variable 10
20/06/06 19:05:12 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 38.8 KB, free 7.5 GB)
20/06/06 19:05:12 INFO TorrentBroadcast: Reading broadcast variable 10 took 143 ms
20/06/06 19:05:12 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 591.5 KB, free 7.5 GB)
20/06/06 19:05:12 INFO CodeGenerator: Code generated in 8.537345 ms
20/06/06 19:05:12 INFO CodeGenerator: Code generated in 64.543298 ms
20/06/06 19:05:12 INFO CodeGenerator: Code generated in 10.466836 ms
20/06/06 19:05:12 INFO CodeGenerator: Code generated in 44.297452 ms
20/06/06 19:05:12 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:05:14 INFO Executor: Finished task 253.0 in stage 7.0 (TID 2222). 2009 bytes result sent to driver
20/06/06 19:05:14 INFO CoarseGrainedExecutorBackend: Got assigned task 2327
20/06/06 19:05:14 INFO Executor: Running task 81.0 in stage 10.0 (TID 2327)
20/06/06 19:05:14 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/customer/tables/customers_preferences/AF002062.customers_preferences.8.gz:0+260905440
20/06/06 19:05:15 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:05:15 INFO Executor: Finished task 5.0 in stage 9.0 (TID 2245). 2404 bytes result sent to driver
20/06/06 19:05:15 INFO CoarseGrainedExecutorBackend: Got assigned task 2338
20/06/06 19:05:15 INFO Executor: Running task 3.0 in stage 13.0 (TID 2338)
20/06/06 19:05:15 INFO TorrentBroadcast: Started reading broadcast variable 31
20/06/06 19:05:15 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-42.us-west-2.compute.internal/10.128.11.42:46645 after 30 ms (0 ms spent in bootstraps)
20/06/06 19:05:16 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 10.6 KB, free 7.5 GB)
20/06/06 19:05:16 INFO TorrentBroadcast: Reading broadcast variable 31 took 155 ms
20/06/06 19:05:16 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 22.0 KB, free 7.5 GB)
20/06/06 19:05:16 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/customer/tables/customers_preferences/AF001837.customers_preferences.12.gz:0+190339628
20/06/06 19:05:16 INFO TorrentBroadcast: Started reading broadcast variable 11
20/06/06 19:05:16 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-148.us-west-2.compute.internal/10.128.11.148:45951 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:05:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 38.8 KB, free 7.5 GB)
20/06/06 19:05:16 INFO TorrentBroadcast: Reading broadcast variable 11 took 79 ms
20/06/06 19:05:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 591.5 KB, free 7.5 GB)
20/06/06 19:05:16 INFO CodeGenerator: Code generated in 69.983192 ms
20/06/06 19:05:16 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:05:16 INFO Executor: Finished task 2.0 in stage 1.0 (TID 1676). 1966 bytes result sent to driver
20/06/06 19:05:16 INFO CoarseGrainedExecutorBackend: Got assigned task 2344
20/06/06 19:05:16 INFO Executor: Running task 9.0 in stage 13.0 (TID 2344)
20/06/06 19:05:16 INFO HadoopRDD: Input split: s3://imvudata/mysql/priority-1/2020-06-05/customer/tables/customers_preferences/AF001837.customers_preferences.3.gz:0+267851557
20/06/06 19:05:16 WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
20/06/06 19:06:01 INFO CodeGenerator: Code generated in 13.023371 ms
20/06/06 19:06:01 INFO CodeGenerator: Code generated in 10.98548 ms
20/06/06 19:06:01 INFO CodeGenerator: Code generated in 28.846726 ms
20/06/06 19:06:03 INFO Executor: Finished task 17.0 in stage 10.0 (TID 2263). 2304 bytes result sent to driver
20/06/06 19:06:03 INFO CoarseGrainedExecutorBackend: Got assigned task 2426
20/06/06 19:06:03 INFO Executor: Running task 5.0 in stage 11.0 (TID 2426)
20/06/06 19:06:03 INFO MapOutputTrackerWorker: Updating epoch to 10 and clearing cache
20/06/06 19:06:03 INFO TorrentBroadcast: Started reading broadcast variable 33
20/06/06 19:06:04 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 33.2 KB, free 9.2 GB)
20/06/06 19:06:04 INFO TorrentBroadcast: Reading broadcast variable 33 took 53 ms
20/06/06 19:06:04 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 97.6 KB, free 9.2 GB)
20/06/06 19:06:04 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/06/06 19:06:04 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:06:04 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:06:04 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks including 2 local blocks and 98 remote blocks
20/06/06 19:06:04 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:7337 after 40 ms (0 ms spent in bootstraps)
20/06/06 19:06:04 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-205.us-west-2.compute.internal/10.128.11.205:7337 after 55 ms (0 ms spent in bootstraps)
20/06/06 19:06:04 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-148.us-west-2.compute.internal/10.128.11.148:7337 after 58 ms (0 ms spent in bootstraps)
20/06/06 19:06:04 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-145.us-west-2.compute.internal/10.128.11.145:7337 after 89 ms (0 ms spent in bootstraps)
20/06/06 19:06:04 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-202.us-west-2.compute.internal/10.128.11.202:7337 after 87 ms (0 ms spent in bootstraps)
20/06/06 19:06:04 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:7337 after 29 ms (0 ms spent in bootstraps)
20/06/06 19:06:04 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-42.us-west-2.compute.internal/10.128.11.42:7337 after 15 ms (0 ms spent in bootstraps)
20/06/06 19:06:04 INFO ShuffleBlockFetcherIterator: Started 22 remote fetches in 630 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 81.302276 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 11.056818 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 6.116185 ms
20/06/06 19:06:05 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
20/06/06 19:06:05 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:06:05 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:06:05 INFO ShuffleBlockFetcherIterator: Getting 18 non-empty blocks including 0 local blocks and 18 remote blocks
20/06/06 19:06:05 INFO ShuffleBlockFetcherIterator: Started 14 remote fetches in 3 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 60.411545 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 6.448394 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 14.949175 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 34.06104 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 18.072611 ms
20/06/06 19:06:05 INFO CodeGenerator: Code generated in 44.749629 ms
20/06/06 19:06:06 INFO CodeGenerator: Code generated in 69.51106 ms
20/06/06 19:06:06 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them
20/06/06 19:06:06 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:06:06 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:06:06 INFO ShuffleBlockFetcherIterator: Getting 265 non-empty blocks including 10 local blocks and 255 remote blocks
20/06/06 19:06:06 INFO ShuffleBlockFetcherIterator: Started 36 remote fetches in 49 ms
20/06/06 19:06:06 INFO CodeGenerator: Code generated in 33.28973 ms
20/06/06 19:06:06 INFO CodeGenerator: Code generated in 37.194228 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 98.219196 ms
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 3, fetching them
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:06:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 0 local blocks and 1 remote blocks
20/06/06 19:06:07 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 30.424945 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 36.967907 ms
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 4, fetching them
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:06:07 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:06:07 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 3 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 47.466849 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 49.600261 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 35.692308 ms
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 5, fetching them
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:06:07 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:06:07 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:06:07 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 13 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 123.288719 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 7.91538 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 11.355811 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 48.22702 ms
20/06/06 19:06:07 INFO CodeGenerator: Code generated in 12.08615 ms
20/06/06 19:06:08 INFO CodeGenerator: Code generated in 45.678649 ms
20/06/06 19:06:10 INFO Executor: Finished task 3.0 in stage 13.0 (TID 2338). 2304 bytes result sent to driver
20/06/06 19:06:10 INFO CoarseGrainedExecutorBackend: Got assigned task 2433
20/06/06 19:06:10 INFO Executor: Running task 12.0 in stage 11.0 (TID 2433)
20/06/06 19:06:10 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks including 2 local blocks and 98 remote blocks
20/06/06 19:06:10 INFO ShuffleBlockFetcherIterator: Started 23 remote fetches in 213 ms
20/06/06 19:06:10 INFO ShuffleBlockFetcherIterator: Getting 18 non-empty blocks including 0 local blocks and 18 remote blocks
20/06/06 19:06:10 INFO ShuffleBlockFetcherIterator: Started 14 remote fetches in 2 ms
20/06/06 19:06:11 INFO ShuffleBlockFetcherIterator: Getting 265 non-empty blocks including 10 local blocks and 255 remote blocks
20/06/06 19:06:11 INFO ShuffleBlockFetcherIterator: Started 36 remote fetches in 81 ms
20/06/06 19:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 0 local blocks and 1 remote blocks
20/06/06 19:06:12 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
20/06/06 19:06:12 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:06:12 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 3 ms
20/06/06 19:06:12 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:06:12 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:06:23 INFO Executor: Finished task 5.0 in stage 11.0 (TID 2426). 7515 bytes result sent to driver
20/06/06 19:06:23 INFO CoarseGrainedExecutorBackend: Got assigned task 2492
20/06/06 19:06:23 INFO Executor: Running task 46.0 in stage 14.0 (TID 2492)
20/06/06 19:06:23 INFO TorrentBroadcast: Started reading broadcast variable 19
20/06/06 19:06:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.6 KB, free 8.3 GB)
20/06/06 19:06:23 INFO TorrentBroadcast: Reading broadcast variable 19 took 22 ms
20/06/06 19:06:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 189.6 KB, free 8.3 GB)
20/06/06 19:06:23 INFO CodeGenerator: Code generated in 145.204423 ms
20/06/06 19:06:23 INFO CodeGenerator: Code generated in 27.551963 ms
20/06/06 19:06:24 INFO CodeGenerator: Code generated in 31.193766 ms
20/06/06 19:06:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=29/000005_0, range: 0-426053, partition values: [2018,6,29]
20/06/06 19:06:24 INFO TorrentBroadcast: Started reading broadcast variable 15
20/06/06 19:06:24 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 39.2 KB, free 8.3 GB)
20/06/06 19:06:24 INFO TorrentBroadcast: Reading broadcast variable 15 took 13 ms
20/06/06 19:06:24 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 595.0 KB, free 8.3 GB)
20/06/06 19:06:24 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:06:25 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=29/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 426053, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:06:25 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:06:25 INFO Executor: Finished task 12.0 in stage 11.0 (TID 2433). 7515 bytes result sent to driver
20/06/06 19:06:25 INFO CoarseGrainedExecutorBackend: Got assigned task 2517
20/06/06 19:06:25 INFO Executor: Running task 67.0 in stage 14.0 (TID 2517)
20/06/06 19:06:25 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=28/000001_0, range: 0-395648, partition values: [2019,9,28]
20/06/06 19:06:26 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:06:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=28/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395648, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:06:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:06:26 INFO Executor: Finished task 81.0 in stage 10.0 (TID 2327). 2304 bytes result sent to driver
20/06/06 19:06:26 INFO CoarseGrainedExecutorBackend: Got assigned task 2522
20/06/06 19:06:26 INFO Executor: Running task 71.0 in stage 14.0 (TID 2522)
20/06/06 19:06:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=15/000008_0, range: 0-390568, partition values: [2018,9,15]
20/06/06 19:06:26 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:06:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=15/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390568, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:06:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:06:27 INFO Executor: Finished task 9.0 in stage 13.0 (TID 2344). 2304 bytes result sent to driver
20/06/06 19:06:27 INFO CoarseGrainedExecutorBackend: Got assigned task 2533
20/06/06 19:06:27 INFO Executor: Running task 82.0 in stage 14.0 (TID 2533)
20/06/06 19:06:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=9/000004_0, range: 0-377453, partition values: [2018,8,9]
20/06/06 19:06:28 INFO OrcCodecPool: Got brand-new codec SNAPPY
20/06/06 19:06:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=9/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377453, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:06:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:06:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=27/000000_0, range: 0-395473, partition values: [2019,2,27]
20/06/06 19:06:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=27/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395473, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:06:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000002_0, range: 0-390496, partition values: [2019,5,27]
20/06/06 19:07:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390496, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=13/000005_0, range: 0-426050, partition values: [2020,5,13]
20/06/06 19:07:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=13/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 426050, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=18/000007_0, range: 0-377440, partition values: [2020,5,18]
20/06/06 19:07:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=18/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377440, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:25 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=2/000002_0, range: 0-390478, partition values: [2020,2,2]
20/06/06 19:07:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=2/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390478, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=5/000000_0, range: 0-395432, partition values: [2018,5,5]
20/06/06 19:07:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=5/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395432, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=3/000003_0, range: 0-426042, partition values: [2018,3,3]
20/06/06 19:07:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=3/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 426042, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=16/000001_0, range: 0-377394, partition values: [2019,5,16]
20/06/06 19:07:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=16/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377394, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:07:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=29/000010_0, range: 0-390473, partition values: [2020,3,29]
20/06/06 19:07:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=29/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390473, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:07:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:01 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=12/000007_0, range: 0-377387, partition values: [2020,5,12]
20/06/06 19:08:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=12/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377387, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=21/000009_0, range: 0-390470, partition values: [2018,7,21]
20/06/06 19:08:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=21/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390470, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:18 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000000_0, range: 0-395394, partition values: [2019,7,28]
20/06/06 19:08:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=28/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395394, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=14/000000_0, range: 0-426014, partition values: [2019,12,14]
20/06/06 19:08:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=14/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 426014, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=5/000003_0, range: 0-377354, partition values: [2019,5,5]
20/06/06 19:08:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=5/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377354, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=14/000002_0, range: 0-395381, partition values: [2020,3,14]
20/06/06 19:08:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=14/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395381, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=30/000008_0, range: 0-390373, partition values: [2018,11,30]
20/06/06 19:08:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=30/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390373, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=8/000007_0, range: 0-377275, partition values: [2018,9,8]
20/06/06 19:08:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=8/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377275, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:08:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=16/000001_0, range: 0-425997, partition values: [2019,6,16]
20/06/06 19:08:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=16/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425997, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:08:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:09:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=29/000008_0, range: 0-395319, partition values: [2018,9,29]
20/06/06 19:09:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=29/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395319, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:09:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:09:16 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=30/000004_0, range: 0-425936, partition values: [2018,6,30]
20/06/06 19:09:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=30/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425936, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:09:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:09:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=3/000008_0, range: 0-377207, partition values: [2020,5,3]
20/06/06 19:09:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=3/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377207, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:09:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:09:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=16/000002_0, range: 0-390181, partition values: [2018,4,16]
20/06/06 19:09:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=16/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390181, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:09:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:09:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=30/000009_0, range: 0-395302, partition values: [2020,4,30]
20/06/06 19:09:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=30/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395302, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:09:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:10:00 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=23/000001_0, range: 0-377186, partition values: [2018,4,23]
20/06/06 19:10:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=23/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377186, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:10:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:10:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=4/000004_0, range: 0-425904, partition values: [2018,11,4]
20/06/06 19:10:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=4/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425904, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:10:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:10:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=27/000008_0, range: 0-395222, partition values: [2018,12,27]
20/06/06 19:10:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=27/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395222, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:10:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:10:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=7/000005_0, range: 0-390165, partition values: [2018,4,7]
20/06/06 19:10:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=7/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390165, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:10:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:10:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=6/000004_0, range: 0-425846, partition values: [2020,5,6]
20/06/06 19:10:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=6/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425846, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:10:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:10:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=12/000000_0, range: 0-377128, partition values: [2018,2,12]
20/06/06 19:10:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=12/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377128, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:10:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:11:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=26/000006_0, range: 0-395200, partition values: [2020,3,26]
20/06/06 19:11:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=26/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395200, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:11:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:11:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=23/000006_0, range: 0-390120, partition values: [2020,5,23]
20/06/06 19:11:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=23/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390120, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:11:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:11:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=12/000003_0, range: 0-425829, partition values: [2018,8,12]
20/06/06 19:11:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=12/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425829, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:11:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:11:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=30/000002_0, range: 0-377054, partition values: [2018,5,30]
20/06/06 19:11:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=2/000009_0, range: 0-395186, partition values: [2020,5,2]
20/06/06 19:11:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=30/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 377054, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:11:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:11:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=2/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395186, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:11:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:11:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=13/000008_0, range: 0-390084, partition values: [2018,10,13]
20/06/06 19:11:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=13/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390084, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:11:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:05 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=25/000004_0, range: 0-395077, partition values: [2018,12,25]
20/06/06 19:12:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=25/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395077, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=27/000006_0, range: 0-376973, partition values: [2018,8,27]
20/06/06 19:12:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=27/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376973, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=8/000003_0, range: 0-425777, partition values: [2018,4,8]
20/06/06 19:12:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=8/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425777, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=19/000000_0, range: 0-390012, partition values: [2017,7,19]
20/06/06 19:12:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=19/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 390012, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=10/000002_0, range: 0-376885, partition values: [2018,8,10]
20/06/06 19:12:39 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=10/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376885, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:39 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=10/000000_0, range: 0-395069, partition values: [2018,4,10]
20/06/06 19:12:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=10/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395069, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:12:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=11/000000_0, range: 0-389979, partition values: [2019,7,11]
20/06/06 19:12:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=11/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389979, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:12:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:01 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=30/000005_0, range: 0-425704, partition values: [2018,12,30]
20/06/06 19:13:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=30/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425704, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000003_0, range: 0-389944, partition values: [2019,1,30]
20/06/06 19:13:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=30/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389944, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=25/000006_0, range: 0-376831, partition values: [2020,5,25]
20/06/06 19:13:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=25/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376831, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000001_0, range: 0-395068, partition values: [2019,5,27]
20/06/06 19:13:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395068, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=30/000001_0, range: 0-395042, partition values: [2017,7,30]
20/06/06 19:13:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=30/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395042, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:13:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=17/000001_0, range: 0-425638, partition values: [2020,3,17]
20/06/06 19:13:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=17/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425638, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:13:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=30/000007_0, range: 0-389935, partition values: [2018,9,30]
20/06/06 19:14:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=30/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389935, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:05 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=6/000007_0, range: 0-376828, partition values: [2018,10,6]
20/06/06 19:14:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=6/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376828, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=5/000003_0, range: 0-395029, partition values: [2019,7,5]
20/06/06 19:14:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=5/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 395029, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:25 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=20/000006_0, range: 0-425570, partition values: [2020,5,20]
20/06/06 19:14:25 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=20/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425570, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:25 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:38 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=19/000003_0, range: 0-376787, partition values: [2020,1,19]
20/06/06 19:14:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=19/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376787, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:38 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=23/000006_0, range: 0-394987, partition values: [2018,11,23]
20/06/06 19:14:39 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=23/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394987, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:39 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=29/000008_0, range: 0-389919, partition values: [2018,12,29]
20/06/06 19:14:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=29/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389919, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:14:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=12/000006_0, range: 0-425568, partition values: [2018,7,12]
20/06/06 19:14:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=12/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425568, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:14:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=18/000012_0, range: 0-376724, partition values: [2018,8,18]
20/06/06 19:15:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=18/000012_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376724, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:19 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=11/000007_0, range: 0-394930, partition values: [2018,11,11]
20/06/06 19:15:20 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=11/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394930, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:20 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=30/000088_0, range: 0-389911, partition values: [2016,12,30]
20/06/06 19:15:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=30/000088_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 389911, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:15:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=19/000001_0, range: 0-389891, partition values: [2019,2,19]
20/06/06 19:15:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=19/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389891, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=30/000003_0, range: 0-425436, partition values: [2018,6,30]
20/06/06 19:15:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=31/000004_0, range: 0-376718, partition values: [2018,8,31]
20/06/06 19:15:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=30/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425436, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:15:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=31/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376718, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:15:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=23/000008_0, range: 0-394897, partition values: [2018,7,23]
20/06/06 19:16:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=23/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394897, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=20/000004_0, range: 0-389855, partition values: [2018,10,20]
20/06/06 19:16:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=20/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389855, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=5/000002_0, range: 0-376688, partition values: [2019,8,5]
20/06/06 19:16:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=5/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376688, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=16/000000_0, range: 0-425381, partition values: [2018,11,16]
20/06/06 19:16:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=16/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425381, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=17/000005_0, range: 0-376674, partition values: [2020,4,17]
20/06/06 19:16:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=17/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376674, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=25/000009_0, range: 0-394875, partition values: [2020,4,25]
20/06/06 19:16:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=25/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394875, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:16:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=30/000006_0, range: 0-389819, partition values: [2018,9,30]
20/06/06 19:16:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=30/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389819, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:16:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=2/000010_0, range: 0-376626, partition values: [2020,5,2]
20/06/06 19:17:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=2/000010_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376626, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=7/000000_0, range: 0-425348, partition values: [2019,12,7]
20/06/06 19:17:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=7/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425348, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:17:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=17/000000_0, range: 0-394799, partition values: [2019,1,17]
20/06/06 19:17:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=17/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394799, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:17:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=30/000094_0, range: 0-376572, partition values: [2016,5,30]
20/06/06 19:18:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=30/000094_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 376572, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:18:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=10/day=1/000092_0, range: 0-376510, partition values: [2016,10,1]
20/06/06 19:18:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=10/day=1/000092_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 376510, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:18:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=28/000000_0, range: 0-376481, partition values: [2019,8,28]
20/06/06 19:18:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=28/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376481, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=27/000001_0, range: 0-425248, partition values: [2019,12,27]
20/06/06 19:18:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=27/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425248, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=28/000005_0, range: 0-389654, partition values: [2018,6,28]
20/06/06 19:18:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=28/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389654, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=27/000009_0, range: 0-376438, partition values: [2020,4,27]
20/06/06 19:18:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=27/000009_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376438, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=26/000003_0, range: 0-425238, partition values: [2018,7,26]
20/06/06 19:18:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=26/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425238, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=16/000002_0, range: 0-394799, partition values: [2019,6,16]
20/06/06 19:18:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=16/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394799, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=29/000005_0, range: 0-389584, partition values: [2018,8,29]
20/06/06 19:18:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=29/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389584, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:18:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=9/000004_0, range: 0-394734, partition values: [2020,5,9]
20/06/06 19:18:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=9/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394734, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:18:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:00 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=10/000001_0, range: 0-376400, partition values: [2019,8,10]
20/06/06 19:19:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=10/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376400, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=30/000006_0, range: 0-425078, partition values: [2020,3,30]
20/06/06 19:19:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=30/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425078, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=7/000001_0, range: 0-376256, partition values: [2018,11,7]
20/06/06 19:19:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=7/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376256, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=2/000001_0, range: 0-389460, partition values: [2019,7,2]
20/06/06 19:19:28 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=2/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389460, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:28 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=22/000004_0, range: 0-394733, partition values: [2020,4,22]
20/06/06 19:19:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=22/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394733, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=21/000004_0, range: 0-425075, partition values: [2019,1,21]
20/06/06 19:19:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=21/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425075, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:19:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=21/000002_0, range: 0-389362, partition values: [2018,12,21]
20/06/06 19:19:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=21/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389362, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:19:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=15/000006_0, range: 0-394732, partition values: [2018,8,15]
20/06/06 19:20:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=15/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394732, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=31/000001_0, range: 0-376236, partition values: [2019,3,31]
20/06/06 19:20:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=31/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376236, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=14/000000_0, range: 0-376199, partition values: [2019,5,14]
20/06/06 19:20:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=14/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376199, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=2/000001_0, range: 0-389361, partition values: [2018,8,2]
20/06/06 19:20:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=2/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389361, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=23/000006_0, range: 0-394725, partition values: [2020,4,23]
20/06/06 19:20:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=15/000006_0, range: 0-425071, partition values: [2018,6,15]
20/06/06 19:20:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=23/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394725, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=15/000006_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 425071, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:20:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=14/000005_0, range: 0-376187, partition values: [2019,4,14]
20/06/06 19:20:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=14/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376187, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:20:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=29/000003_0, range: 0-376066, partition values: [2018,5,29]
20/06/06 19:21:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=29/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 376066, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:18 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=6/day=25/000087_0, range: 0-394721, partition values: [2016,6,25]
20/06/06 19:21:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=6/day=25/000087_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 394721, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:21:19 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=14/000008_0, range: 0-394701, partition values: [2020,4,14]
20/06/06 19:21:20 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=14/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394701, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:20 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=31/000000_0, range: 0-389325, partition values: [2019,1,31]
20/06/06 19:21:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=31/000000_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389325, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=12/000005_0, range: 0-424994, partition values: [2018,7,12]
20/06/06 19:21:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=12/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 424994, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:46 INFO CodeGenerator: Code generated in 7.5191 ms
20/06/06 19:21:46 INFO CodeGenerator: Code generated in 8.413989 ms
20/06/06 19:21:46 INFO CodeGenerator: Code generated in 5.867861 ms
20/06/06 19:21:46 INFO CodeGenerator: Code generated in 6.26827 ms
20/06/06 19:21:46 INFO CodeGenerator: Code generated in 13.16472 ms
20/06/06 19:21:46 INFO Executor: Finished task 82.0 in stage 14.0 (TID 2533). 2548 bytes result sent to driver
20/06/06 19:21:46 INFO CoarseGrainedExecutorBackend: Got assigned task 3793
20/06/06 19:21:46 INFO Executor: Running task 975.0 in stage 14.0 (TID 3793)
20/06/06 19:21:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=25/000021_0, range: 0-105881, partition values: [2018,10,25]
20/06/06 19:21:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=25/000021_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105881, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=24/000005_0, range: 0-394642, partition values: [2020,4,24]
20/06/06 19:21:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=24/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394642, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:21:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:21:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=31/000024_0, range: 0-105881, partition values: [2019,3,31]
20/06/06 19:22:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=31/000024_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105881, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=19/000028_0, range: 0-105878, partition values: [2018,8,19]
20/06/06 19:22:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=19/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105878, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=31/000005_0, range: 0-424990, partition values: [2020,3,31]
20/06/06 19:22:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=31/000005_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 424990, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=30/000008_0, range: 0-389295, partition values: [2020,3,30]
20/06/06 19:22:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=30/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389295, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:19 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=27/000021_0, range: 0-105875, partition values: [2019,2,27]
20/06/06 19:22:19 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=27/000021_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105875, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:19 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=15/000007_0, range: 0-394569, partition values: [2018,8,15]
20/06/06 19:22:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=15/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394569, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=27/001749_0, range: 0-105874, partition values: [2016,5,27]
20/06/06 19:22:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=27/001749_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 105874, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:22:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=27/000017_0, range: 0-105867, partition values: [2017,2,27]
20/06/06 19:22:33 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=27/000017_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 105867, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:33 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:22:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=30/000026_0, range: 0-105867, partition values: [2018,6,30]
20/06/06 19:22:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=30/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105867, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=16/000007_0, range: 0-389287, partition values: [2018,8,16]
20/06/06 19:22:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=16/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389287, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=20/000003_0, range: 0-424889, partition values: [2018,8,20]
20/06/06 19:22:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=20/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 424889, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:22:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=4/001718_0, range: 0-105853, partition values: [2016,4,4]
20/06/06 19:22:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=4/001718_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 105853, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:22:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=31/000013_0, range: 0-105835, partition values: [2017,3,31]
20/06/06 19:22:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=31/000013_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 105835, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:22:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=5/000028_0, range: 0-105831, partition values: [2018,7,5]
20/06/06 19:22:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=5/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105831, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:22:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:00 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=7/000004_0, range: 0-394566, partition values: [2018,10,7]
20/06/06 19:23:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=7/000004_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 394566, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=1/000022_0, range: 0-105830, partition values: [2019,4,1]
20/06/06 19:23:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=1/000022_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105830, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=4/000034_0, range: 0-105829, partition values: [2018,3,4]
20/06/06 19:23:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=4/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105829, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=21/000001_0, range: 0-389282, partition values: [2019,2,21]
20/06/06 19:23:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=21/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389282, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=8/000007_0, range: 0-424851, partition values: [2020,4,8]
20/06/06 19:23:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=8/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 424851, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:23:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=31/000017_0, range: 0-105825, partition values: [2017,12,31]
20/06/06 19:23:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=31/000017_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105825, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:23:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=29/000026_0, range: 0-105820, partition values: [2019,7,29]
20/06/06 19:24:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=29/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105820, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=31/000026_0, range: 0-105813, partition values: [2019,5,31]
20/06/06 19:24:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=31/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105813, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:16 INFO Executor: Finished task 67.0 in stage 14.0 (TID 2517). 2548 bytes result sent to driver
20/06/06 19:24:16 INFO CoarseGrainedExecutorBackend: Got assigned task 4268
20/06/06 19:24:16 INFO Executor: Running task 1450.0 in stage 14.0 (TID 4268)
20/06/06 19:24:16 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=23/000033_0, range: 0-53732, partition values: [2019,8,23]
20/06/06 19:24:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=23/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53732, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:19 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=20/003526_0, range: 0-53730, partition values: [2016,1,20]
20/06/06 19:24:19 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=20/003526_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53730, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:19 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:20 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=21/000034_0, range: 0-53728, partition values: [2017,6,21]
20/06/06 19:24:20 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=21/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53728, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:20 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=16/000023_0, range: 0-105812, partition values: [2019,1,16]
20/06/06 19:24:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=16/000023_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105812, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=25/000034_0, range: 0-53728, partition values: [2019,2,25]
20/06/06 19:24:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=25/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53728, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=5/000008_0, range: 0-389240, partition values: [2020,5,5]
20/06/06 19:24:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=5/000008_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389240, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=14/000031_0, range: 0-53724, partition values: [2020,2,14]
20/06/06 19:24:31 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=14/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53724, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:31 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=29/000002_0, range: 0-424828, partition values: [2019,6,29]
20/06/06 19:24:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=29/000002_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 424828, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=12/000027_0, range: 0-105812, partition values: [2019,5,12]
20/06/06 19:24:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=22/000030_0, range: 0-53723, partition values: [2017,1,22]
20/06/06 19:24:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=12/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105812, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=22/000030_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53723, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:38 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=4/000023_0, range: 0-53721, partition values: [2017,10,4]
20/06/06 19:24:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=4/000023_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53721, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=5/000033_0, range: 0-105807, partition values: [2020,4,5]
20/06/06 19:24:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=5/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105807, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=6/day=15/003591_0, range: 0-53717, partition values: [2016,6,15]
20/06/06 19:24:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=6/day=15/003591_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53717, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:24:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=19/000037_0, range: 0-53714, partition values: [2020,3,19]
20/06/06 19:24:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=19/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53714, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=17/000028_0, range: 0-53712, partition values: [2017,10,17]
20/06/06 19:24:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=26/000022_0, range: 0-105792, partition values: [2019,3,26]
20/06/06 19:24:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=17/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53712, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=26/000022_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105792, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=2/000035_0, range: 0-53707, partition values: [2018,1,2]
20/06/06 19:24:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=2/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53707, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:24:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=25/000024_0, range: 0-105787, partition values: [2019,1,25]
20/06/06 19:24:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=25/000024_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105787, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:24:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=21/000003_0, range: 0-389066, partition values: [2018,8,21]
20/06/06 19:25:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=21/000003_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 389066, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:05 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=30/000007_0, range: 0-424825, partition values: [2020,4,30]
20/06/06 19:25:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=30/000007_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 424825, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=23/003592_0, range: 0-53706, partition values: [2016,5,23]
20/06/06 19:25:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=23/003592_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53706, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=23/000040_0, range: 0-53706, partition values: [2020,4,23]
20/06/06 19:25:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=23/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53706, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=12/000024_0, range: 0-105782, partition values: [2020,1,12]
20/06/06 19:25:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=12/000024_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105782, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=31/003593_0, range: 0-53706, partition values: [2016,5,31]
20/06/06 19:25:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=5/day=31/003593_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53706, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=26/000029_0, range: 0-53705, partition values: [2019,3,26]
20/06/06 19:25:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=26/000029_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53705, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:19 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=15/000039_0, range: 0-53695, partition values: [2019,2,15]
20/06/06 19:25:19 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=15/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53695, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:19 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=9/000015_0, range: 0-105765, partition values: [2017,5,9]
20/06/06 19:25:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=9/000015_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105765, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=24/000029_0, range: 0-53691, partition values: [2017,9,24]
20/06/06 19:25:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=24/000029_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53691, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=16/001779_0, range: 0-105763, partition values: [2016,7,16]
20/06/06 19:25:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=28/000030_0, range: 0-53688, partition values: [2019,8,28]
20/06/06 19:25:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=16/001779_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 105763, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=28/000030_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53688, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=15/000028_0, range: 0-105759, partition values: [2019,5,15]
20/06/06 19:25:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=15/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105759, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:33 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=23/000032_0, range: 0-53687, partition values: [2017,5,23]
20/06/06 19:25:33 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=23/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53687, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:33 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=1/000025_0, range: 0-105759, partition values: [2018,3,1]
20/06/06 19:25:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=1/000025_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105759, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=15/000028_0, range: 0-53680, partition values: [2017,9,15]
20/06/06 19:25:36 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=15/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53680, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:36 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=14/000001_0, range: 0-424824, partition values: [2018,6,14]
20/06/06 19:25:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=14/000001_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 424824, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=9/000036_0, range: 0-53680, partition values: [2017,7,9]
20/06/06 19:25:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=9/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53680, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:45 INFO Executor: Finished task 71.0 in stage 14.0 (TID 2522). 2548 bytes result sent to driver
20/06/06 19:25:45 INFO CoarseGrainedExecutorBackend: Got assigned task 4434
20/06/06 19:25:45 INFO Executor: Running task 1616.0 in stage 14.0 (TID 4434)
20/06/06 19:25:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=31/000041_0, range: 0-40671, partition values: [2018,8,31]
20/06/06 19:25:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=16/003594_0, range: 0-53677, partition values: [2016,4,16]
20/06/06 19:25:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=31/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40671, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=16/003594_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53677, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:46 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=10/day=7/003538_0, range: 0-53676, partition values: [2016,10,7]
20/06/06 19:25:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=10/day=7/003538_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53676, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=16/000027_0, range: 0-53669, partition values: [2019,9,16]
20/06/06 19:25:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=16/000027_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53669, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=28/000025_0, range: 0-105757, partition values: [2018,1,28]
20/06/06 19:25:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=28/000025_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105757, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=29/000039_0, range: 0-40668, partition values: [2019,5,29]
20/06/06 19:25:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=29/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40668, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=3/000031_0, range: 0-40668, partition values: [2019,10,3]
20/06/06 19:25:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=3/000031_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40668, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=15/000030_0, range: 0-53669, partition values: [2017,1,15]
20/06/06 19:25:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=15/000030_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53669, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=1/004308_0, range: 0-40666, partition values: [2016,4,1]
20/06/06 19:25:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=1/004308_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 40666, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=8/000033_0, range: 0-53666, partition values: [2017,12,8]
20/06/06 19:25:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=8/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53666, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=11/day=30/004309_0, range: 0-40665, partition values: [2016,11,30]
20/06/06 19:25:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=11/day=30/004309_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 40665, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=7/004310_0, range: 0-40665, partition values: [2016,7,7]
20/06/06 19:25:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=7/004310_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 40665, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:25:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=9/000032_0, range: 0-40665, partition values: [2019,12,9]
20/06/06 19:25:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=9/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40665, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:25:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=1/000038_0, range: 0-40663, partition values: [2018,1,1]
20/06/06 19:25:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=1/day=1/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40663, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:25:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=9/003595_0, range: 0-53665, partition values: [2016,4,9]
20/06/06 19:26:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=18/000025_0, range: 0-105754, partition values: [2017,7,18]
20/06/06 19:26:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=9/003595_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53665, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=18/000025_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105754, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=9/003596_0, range: 0-53664, partition values: [2016,12,9]
20/06/06 19:26:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=9/003596_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53664, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=15/000026_0, range: 0-53664, partition values: [2019,10,15]
20/06/06 19:26:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=15/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53664, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=16/000029_0, range: 0-40663, partition values: [2017,10,16]
20/06/06 19:26:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=16/000029_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40663, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=15/000039_0, range: 0-53662, partition values: [2020,4,15]
20/06/06 19:26:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=15/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53662, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=25/000040_0, range: 0-40659, partition values: [2019,1,25]
20/06/06 19:26:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=25/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40659, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=15/000035_0, range: 0-105745, partition values: [2018,4,15]
20/06/06 19:26:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=15/000035_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105745, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=10/000032_0, range: 0-53660, partition values: [2017,3,10]
20/06/06 19:26:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=10/000032_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 53660, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=6/000039_0, range: 0-40656, partition values: [2018,8,6]
20/06/06 19:26:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=6/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40656, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=7/000043_0, range: 0-53655, partition values: [2018,4,7]
20/06/06 19:26:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=7/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 53655, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:18 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=7/000044_0, range: 0-40651, partition values: [2018,6,7]
20/06/06 19:26:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=7/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40651, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:21 INFO Executor: Finished task 1450.0 in stage 14.0 (TID 4268). 2548 bytes result sent to driver
20/06/06 19:26:21 INFO CoarseGrainedExecutorBackend: Got assigned task 4772
20/06/06 19:26:21 INFO Executor: Running task 1954.0 in stage 14.0 (TID 4772)
20/06/06 19:26:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=5/000045_0, range: 0-20219, partition values: [2020,1,5]
20/06/06 19:26:21 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=8/000026_0, range: 0-105744, partition values: [2018,9,8]
20/06/06 19:26:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=5/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20219, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:21 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=8/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105744, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:21 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=13/000038_0, range: 0-40646, partition values: [2019,4,13]
20/06/06 19:26:22 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=13/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40646, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:22 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:23 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=21/000043_0, range: 0-20216, partition values: [2020,1,21]
20/06/06 19:26:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=21/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20216, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=2/000043_0, range: 0-40645, partition values: [2018,3,2]
20/06/06 19:26:24 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=2/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40645, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:24 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:24 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=30/000047_0, range: 0-20216, partition values: [2019,4,30]
20/06/06 19:26:25 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=30/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20216, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:25 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:26 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=12/005600_0, range: 0-20213, partition values: [2016,2,12]
20/06/06 19:26:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=12/005600_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 20213, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=10/000045_0, range: 0-20209, partition values: [2020,2,10]
20/06/06 19:26:27 INFO Executor: Finished task 46.0 in stage 14.0 (TID 2492). 2548 bytes result sent to driver
20/06/06 19:26:27 INFO CoarseGrainedExecutorBackend: Got assigned task 4841
20/06/06 19:26:27 INFO Executor: Running task 2023.0 in stage 14.0 (TID 4841)
20/06/06 19:26:27 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000049_0, range: 0-16863, partition values: [2019,5,27]
20/06/06 19:26:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=10/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20209, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:27 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16863, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:27 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:28 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=24/000048_0, range: 0-16860, partition values: [2018,8,24]
20/06/06 19:26:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=24/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16860, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=10/000045_0, range: 0-20208, partition values: [2018,5,10]
20/06/06 19:26:29 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=13/000036_0, range: 0-40645, partition values: [2018,8,13]
20/06/06 19:26:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=10/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20208, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:29 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=8/day=13/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40645, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:29 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:30 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=12/000049_0, range: 0-16859, partition values: [2019,10,12]
20/06/06 19:26:30 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=12/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16859, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:30 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:31 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=22/000049_0, range: 0-16859, partition values: [2017,6,22]
20/06/06 19:26:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=6/day=22/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16859, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=1/000051_0, range: 0-20207, partition values: [2020,5,1]
20/06/06 19:26:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=2/000026_0, range: 0-105744, partition values: [2018,11,2]
20/06/06 19:26:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=1/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20207, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:32 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=2/000026_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 105744, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:32 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:32 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=20/000046_0, range: 0-16858, partition values: [2017,4,20]
20/06/06 19:26:33 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=20/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16858, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:33 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:33 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=21/000036_0, range: 0-20206, partition values: [2017,3,21]
20/06/06 19:26:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=21/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 20206, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=21/000048_0, range: 0-16858, partition values: [2019,12,21]
20/06/06 19:26:34 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=23/000039_0, range: 0-40640, partition values: [2017,12,23]
20/06/06 19:26:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=21/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16858, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:34 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=23/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40640, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:34 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=25/000045_0, range: 0-20206, partition values: [2019,2,25]
20/06/06 19:26:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=25/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20206, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:35 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=25/000043_0, range: 0-16856, partition values: [2019,10,25]
20/06/06 19:26:35 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=25/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16856, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:35 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:36 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=17/000042_0, range: 0-16853, partition values: [2017,4,17]
20/06/06 19:26:37 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=4/day=17/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16853, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:37 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:37 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=20/000043_0, range: 0-20206, partition values: [2020,2,20]
20/06/06 19:26:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=20/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20206, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:38 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=12/000045_0, range: 0-16852, partition values: [2019,6,12]
20/06/06 19:26:38 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=12/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16852, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:38 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=1/000042_0, range: 0-20203, partition values: [2018,2,1]
20/06/06 19:26:39 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=1/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20203, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:39 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:39 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=22/000043_0, range: 0-16850, partition values: [2017,1,22]
20/06/06 19:26:40 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=22/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 16850, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:40 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:40 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=1/000033_0, range: 0-40640, partition values: [2017,11,1]
20/06/06 19:26:41 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=20/000046_0, range: 0-16846, partition values: [2019,6,20]
20/06/06 19:26:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=1/000033_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40640, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:41 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=20/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16846, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:41 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:42 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000050_0, range: 0-16846, partition values: [2019,5,27]
20/06/06 19:26:42 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=27/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16846, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:42 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=21/000041_0, range: 0-20201, partition values: [2019,10,21]
20/06/06 19:26:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=8/day=14/001780_0, range: 0-105742, partition values: [2016,8,14]
20/06/06 19:26:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=21/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20201, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=8/day=14/001780_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 105742, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=12/000041_0, range: 0-16844, partition values: [2018,9,12]
20/06/06 19:26:43 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=17/000016_0, range: 0-105730, partition values: [2017,2,17]
20/06/06 19:26:43 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=12/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16844, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:43 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=17/000016_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 105730, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:44 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=18/005601_0, range: 0-20200, partition values: [2016,7,18]
20/06/06 19:26:44 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=7/day=18/005601_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 20200, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:44 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=2/000040_0, range: 0-20200, partition values: [2017,10,2]
20/06/06 19:26:45 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=10/day=2/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20200, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:45 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:45 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=15/000048_0, range: 0-16844, partition values: [2018,7,15]
20/06/06 19:26:46 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=15/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16844, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:46 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=19/000036_0, range: 0-40640, partition values: [2019,8,19]
20/06/06 19:26:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=19/000036_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40640, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=29/000046_0, range: 0-16841, partition values: [2019,3,29]
20/06/06 19:26:47 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=5/000046_0, range: 0-20197, partition values: [2019,6,5]
20/06/06 19:26:47 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=29/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16841, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:47 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=5/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20197, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:48 INFO Executor: Finished task 975.0 in stage 14.0 (TID 3793). 2548 bytes result sent to driver
20/06/06 19:26:48 INFO CoarseGrainedExecutorBackend: Got assigned task 5025
20/06/06 19:26:48 INFO Executor: Running task 2207.0 in stage 14.0 (TID 5025)
20/06/06 19:26:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=25/000055_0, range: 0-9156, partition values: [2019,7,25]
20/06/06 19:26:48 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=25/000055_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9156, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:48 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:48 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=6/000044_0, range: 0-16836, partition values: [2019,12,6]
20/06/06 19:26:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=17/000057_0, range: 0-9155, partition values: [2020,3,17]
20/06/06 19:26:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=22/000052_0, range: 0-20196, partition values: [2020,5,22]
20/06/06 19:26:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=12/day=6/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16836, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=17/000057_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9155, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=22/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20196, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=23/000047_0, range: 0-9155, partition values: [2020,1,23]
20/06/06 19:26:49 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=27/004311_0, range: 0-40640, partition values: [2016,4,27]
20/06/06 19:26:49 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=23/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9155, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:49 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=27/004311_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 40640, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=19/000054_0, range: 0-9153, partition values: [2019,5,19]
20/06/06 19:26:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=12/000039_0, range: 0-40636, partition values: [2019,2,12]
20/06/06 19:26:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=5/day=19/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9153, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=9/000051_0, range: 0-16834, partition values: [2019,8,9]
20/06/06 19:26:50 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=21/000048_0, range: 0-20195, partition values: [2020,3,21]
20/06/06 19:26:50 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=12/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40636, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:50 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=9/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16834, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:51 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=7/000051_0, range: 0-9152, partition values: [2018,5,7]
20/06/06 19:26:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=21/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20195, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:51 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=5/day=7/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9152, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:51 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=2/000049_0, range: 0-16833, partition values: [2019,7,2]
20/06/06 19:26:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=2/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16833, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=17/000058_0, range: 0-9152, partition values: [2020,3,17]
20/06/06 19:26:52 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=13/000042_0, range: 0-20189, partition values: [2017,9,13]
20/06/06 19:26:52 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=17/000058_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9152, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:52 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=13/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20189, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=5/000054_0, range: 0-9151, partition values: [2019,7,5]
20/06/06 19:26:53 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=28/000042_0, range: 0-16830, partition values: [2017,9,28]
20/06/06 19:26:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=5/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9151, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:53 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=9/day=28/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16830, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:53 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=18/000048_0, range: 0-9150, partition values: [2019,10,18]
20/06/06 19:26:54 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=18/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9150, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:54 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:54 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=13/000051_0, range: 0-9148, partition values: [2017,5,13]
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=11/day=26/005602_0, range: 0-20187, partition values: [2016,11,26]
20/06/06 19:26:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=13/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9148, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=15/000046_0, range: 0-16829, partition values: [2019,10,15]
20/06/06 19:26:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=11/day=26/005602_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 20187, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=15/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16829, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=28/006243_0, range: 0-9148, partition values: [2016,1,28]
20/06/06 19:26:55 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=28/006243_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 9148, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:55 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:55 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=14/000042_0, range: 0-20186, partition values: [2020,1,14]
20/06/06 19:26:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=14/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20186, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=30/000056_0, range: 0-9148, partition values: [2019,3,30]
20/06/06 19:26:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=14/000047_0, range: 0-16829, partition values: [2018,9,14]
20/06/06 19:26:56 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=5/000039_0, range: 0-40636, partition values: [2019,4,5]
20/06/06 19:26:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=30/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9148, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=14/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16829, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:56 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=5/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40636, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:56 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=13/000042_0, range: 0-9148, partition values: [2017,1,13]
20/06/06 19:26:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=1/day=13/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 9148, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=11/000045_0, range: 0-20185, partition values: [2017,11,11]
20/06/06 19:26:57 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=26/000054_0, range: 0-9148, partition values: [2019,1,26]
20/06/06 19:26:57 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=11/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20185, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:57 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=26/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9148, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=13/000048_0, range: 0-16826, partition values: [2019,8,13]
20/06/06 19:26:58 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=13/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16826, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:58 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:58 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=19/006244_0, range: 0-9147, partition values: [2016,2,19]
20/06/06 19:26:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=19/006244_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 9147, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=22/000042_0, range: 0-40635, partition values: [2018,11,22]
20/06/06 19:26:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=11/day=22/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40635, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:26:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=22/006245_0, range: 0-9147, partition values: [2016,4,22]
20/06/06 19:26:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=25/000050_0, range: 0-16823, partition values: [2019,7,25]
20/06/06 19:26:59 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=4/day=22/006245_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 9147, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:26:59 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:26:59 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=13/000044_0, range: 0-20183, partition values: [2018,9,13]
20/06/06 19:27:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=25/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16823, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:00 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=25/000052_0, range: 0-9146, partition values: [2019,8,25]
20/06/06 19:27:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=9/day=13/000044_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20183, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:00 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=25/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9146, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:00 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:00 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=8/000049_0, range: 0-9143, partition values: [2017,12,8]
20/06/06 19:27:01 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=20/000054_0, range: 0-16822, partition values: [2019,1,20]
20/06/06 19:27:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=12/day=8/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9143, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:01 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=20/000054_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16822, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:01 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=17/000055_0, range: 0-9142, partition values: [2019,8,17]
20/06/06 19:27:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=26/000049_0, range: 0-20182, partition values: [2020,4,26]
20/06/06 19:27:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=8/day=17/000055_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9142, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:02 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=4/day=26/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20182, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:02 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:02 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=30/000048_0, range: 0-9142, partition values: [2018,10,30]
20/06/06 19:27:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=10/day=30/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9142, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=24/000041_0, range: 0-40623, partition values: [2020,5,24]
20/06/06 19:27:03 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=29/000053_0, range: 0-16822, partition values: [2018,12,29]
20/06/06 19:27:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=24/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40623, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:03 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=12/day=29/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16822, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:03 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=12/000040_0, range: 0-20181, partition values: [2017,3,12]
20/06/06 19:27:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=26/000055_0, range: 0-9142, partition values: [2019,6,26]
20/06/06 19:27:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=26/000055_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9142, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:04 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=3/day=12/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 20181, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:04 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:04 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=25/000053_0, range: 0-9142, partition values: [2019,1,25]
20/06/06 19:27:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=25/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9142, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:05 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=20/000046_0, range: 0-20180, partition values: [2019,2,20]
20/06/06 19:27:05 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=20/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20180, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:05 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:05 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=25/000043_0, range: 0-16821, partition values: [2019,9,25]
20/06/06 19:27:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=16/000049_0, range: 0-9141, partition values: [2017,5,16]
20/06/06 19:27:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=9/day=25/000043_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16821, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:06 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=5/day=16/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9141, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:06 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=23/000051_0, range: 0-9141, partition values: [2020,2,23]
20/06/06 19:27:06 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=4/004312_0, range: 0-40621, partition values: [2016,12,4]
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=23/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9141, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=13/000051_0, range: 0-16818, partition values: [2017,7,13]
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=12/day=4/004312_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 40621, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=27/000045_0, range: 0-20177, partition values: [2018,2,27]
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=13/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16818, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=13/000056_0, range: 0-9141, partition values: [2019,6,13]
20/06/06 19:27:07 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=18/000040_0, range: 0-40617, partition values: [2019,4,18]
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=2/day=27/000045_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20177, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=13/000056_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9141, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:07 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=18/000040_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40617, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:07 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=29/000053_0, range: 0-9139, partition values: [2020,3,29]
20/06/06 19:27:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=3/day=29/000053_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9139, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:08 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=21/000052_0, range: 0-16813, partition values: [2018,4,21]
20/06/06 19:27:08 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=4/day=21/000052_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16813, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:08 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=2/000049_0, range: 0-9139, partition values: [2019,11,2]
20/06/06 19:27:09 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=2/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9139, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:09 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:09 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=15/006246_0, range: 0-9138, partition values: [2016,2,15]
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=7/000028_0, range: 0-40615, partition values: [2017,2,7]
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=3/day=22/005603_0, range: 0-20175, partition values: [2016,3,22]
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=2/day=15/006246_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 9138, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=7/000028_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 40615, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=16/000050_0, range: 0-16811, partition values: [2018,7,16]
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=3/day=22/005603_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 20175, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=20/000050_0, range: 0-9134, partition values: [2017,11,20]
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=7/day=16/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16811, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:10 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=20/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9134, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:10 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:10 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=24/000047_0, range: 0-20174, partition values: [2017,11,24]
20/06/06 19:27:11 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=11/day=24/000047_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20174, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:11 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:11 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=28/000048_0, range: 0-9133, partition values: [2020,2,28]
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=2/day=28/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9133, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=5/000042_0, range: 0-16811, partition values: [2019,11,5]
20/06/06 19:27:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=24/000034_0, range: 0-40615, partition values: [2019,3,24]
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=11/day=5/000042_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16811, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:12 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=24/000050_0, range: 0-9133, partition values: [2019,6,24]
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=24/000034_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40615, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:12 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=6/day=24/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9133, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:12 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=5/000058_0, range: 0-9133, partition values: [2019,1,5]
20/06/06 19:27:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=1/day=5/000058_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9133, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=15/000049_0, range: 0-20172, partition values: [2019,2,15]
20/06/06 19:27:13 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=17/000049_0, range: 0-16808, partition values: [2019,3,17]
20/06/06 19:27:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=2/day=15/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20172, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:13 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=3/day=17/000049_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16808, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:13 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=23/000048_0, range: 0-9133, partition values: [2020,1,23]
20/06/06 19:27:14 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=29/000051_0, range: 0-16805, partition values: [2019,7,29]
20/06/06 19:27:14 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=1/day=23/000048_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 9133, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:14 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=3/000041_0, range: 0-40614, partition values: [2020,5,3]
20/06/06 19:27:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=7/day=29/000051_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 16805, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:15 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2020/month=5/day=3/000041_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40614, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:15 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:15 INFO Executor: Finished task 2207.0 in stage 14.0 (TID 5025). 2548 bytes result sent to driver
20/06/06 19:27:15 INFO CoarseGrainedExecutorBackend: Got assigned task 5292
20/06/06 19:27:15 INFO Executor: Running task 200.0 in stage 15.0 (TID 5292)
20/06/06 19:27:15 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/user_country_dim/000032_0:335544320+13061269
20/06/06 19:27:15 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=19/000046_0, range: 0-20171, partition values: [2019,10,19]
20/06/06 19:27:16 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=10/day=19/000046_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20171, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:16 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:16 INFO Executor: Finished task 200.0 in stage 15.0 (TID 5292). 2361 bytes result sent to driver
20/06/06 19:27:16 INFO CoarseGrainedExecutorBackend: Got assigned task 5318
20/06/06 19:27:16 INFO Executor: Running task 7.0 in stage 18.0 (TID 5318)
20/06/06 19:27:16 INFO TorrentBroadcast: Started reading broadcast variable 20
20/06/06 19:27:16 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 69.3 KB, free 9.2 GB)
20/06/06 19:27:16 INFO TorrentBroadcast: Reading broadcast variable 20 took 3 ms
20/06/06 19:27:16 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 437.1 KB, free 9.2 GB)
20/06/06 19:27:16 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=430/000000_0.gz:0+2425556
20/06/06 19:27:16 INFO TorrentBroadcast: Started reading broadcast variable 14
20/06/06 19:27:16 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 39.1 KB, free 9.2 GB)
20/06/06 19:27:16 INFO TorrentBroadcast: Reading broadcast variable 14 took 3 ms
20/06/06 19:27:16 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 591.5 KB, free 9.2 GB)
20/06/06 19:27:16 INFO Executor: Finished task 2023.0 in stage 14.0 (TID 4841). 2548 bytes result sent to driver
20/06/06 19:27:16 INFO CoarseGrainedExecutorBackend: Got assigned task 5327
20/06/06 19:27:16 INFO Executor: Running task 16.0 in stage 18.0 (TID 5327)
20/06/06 19:27:16 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=60/000000_0.gz:0+1978193
20/06/06 19:27:16 INFO CodeGenerator: Code generated in 8.630817 ms
20/06/06 19:27:17 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=1/000037_0, range: 0-20168, partition values: [2017,2,1]
20/06/06 19:27:17 INFO Executor: Finished task 16.0 in stage 18.0 (TID 5327). 1923 bytes result sent to driver
20/06/06 19:27:17 INFO CoarseGrainedExecutorBackend: Got assigned task 5374
20/06/06 19:27:17 INFO Executor: Running task 63.0 in stage 18.0 (TID 5374)
20/06/06 19:27:17 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=64/000000_0.gz:0+1978464
20/06/06 19:27:17 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=2/day=1/000037_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 20168, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:17 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:17 INFO Executor: Finished task 7.0 in stage 18.0 (TID 5318). 1966 bytes result sent to driver
20/06/06 19:27:17 INFO CoarseGrainedExecutorBackend: Got assigned task 5385
20/06/06 19:27:17 INFO Executor: Running task 74.0 in stage 18.0 (TID 5385)
20/06/06 19:27:17 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=261/000000_0.gz:0+3738560
20/06/06 19:27:18 INFO Executor: Finished task 63.0 in stage 18.0 (TID 5374). 1923 bytes result sent to driver
20/06/06 19:27:18 INFO CoarseGrainedExecutorBackend: Got assigned task 5461
20/06/06 19:27:18 INFO Executor: Running task 150.0 in stage 18.0 (TID 5461)
20/06/06 19:27:18 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=65/000000_0.gz:0+1976157
20/06/06 19:27:18 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=25/000038_0, range: 0-40613, partition values: [2018,6,25]
20/06/06 19:27:18 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=21/000050_0, range: 0-20167, partition values: [2019,4,21]
20/06/06 19:27:18 INFO Executor: Finished task 74.0 in stage 18.0 (TID 5385). 1923 bytes result sent to driver
20/06/06 19:27:18 INFO CoarseGrainedExecutorBackend: Got assigned task 5524
20/06/06 19:27:18 INFO Executor: Running task 213.0 in stage 18.0 (TID 5524)
20/06/06 19:27:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=6/day=25/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40613, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:18 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=227/000000_0.gz:0+3762454
20/06/06 19:27:18 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2019/month=4/day=21/000050_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 20167, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:18 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:19 INFO Executor: Finished task 150.0 in stage 18.0 (TID 5461). 1923 bytes result sent to driver
20/06/06 19:27:19 INFO CoarseGrainedExecutorBackend: Got assigned task 5610
20/06/06 19:27:19 INFO Executor: Running task 299.0 in stage 18.0 (TID 5610)
20/06/06 19:27:19 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=424/000000_0.gz:0+2317161
20/06/06 19:27:19 INFO Executor: Finished task 213.0 in stage 18.0 (TID 5524). 1923 bytes result sent to driver
20/06/06 19:27:19 INFO CoarseGrainedExecutorBackend: Got assigned task 5741
20/06/06 19:27:19 INFO Executor: Running task 430.0 in stage 18.0 (TID 5741)
20/06/06 19:27:19 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=378/000000_0.gz:0+2395176
20/06/06 19:27:20 INFO Executor: Finished task 1954.0 in stage 14.0 (TID 4772). 2548 bytes result sent to driver
20/06/06 19:27:20 INFO CoarseGrainedExecutorBackend: Got assigned task 5776
20/06/06 19:27:20 INFO Executor: Running task 465.0 in stage 18.0 (TID 5776)
20/06/06 19:27:20 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=27/000000_0.gz:0+1973911
20/06/06 19:27:20 INFO Executor: Finished task 299.0 in stage 18.0 (TID 5610). 1923 bytes result sent to driver
20/06/06 19:27:20 INFO CoarseGrainedExecutorBackend: Got assigned task 5838
20/06/06 19:27:20 INFO Executor: Running task 527.0 in stage 18.0 (TID 5838)
20/06/06 19:27:20 INFO HadoopRDD: Input split: s3://imvudata/user/hive/warehouse/analysts_shared.db/publisher_dim/cust_id_div_500000=54/000000_0.gz:0+1979392
20/06/06 19:27:21 INFO Executor: Finished task 465.0 in stage 18.0 (TID 5776). 1923 bytes result sent to driver
20/06/06 19:27:21 INFO CoarseGrainedExecutorBackend: Got assigned task 5990
20/06/06 19:27:21 INFO Executor: Running task 25.0 in stage 19.0 (TID 5990)
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Updating epoch to 13 and clearing cache
20/06/06 19:27:21 INFO TorrentBroadcast: Started reading broadcast variable 34
20/06/06 19:27:21 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 46.9 KB, free 9.2 GB)
20/06/06 19:27:21 INFO TorrentBroadcast: Reading broadcast variable 34 took 21 ms
20/06/06 19:27:21 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 136.7 KB, free 9.2 GB)
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 6, fetching them
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:21 INFO TransportClientFactory: Found inactive connection to ip-10-128-11-148.us-west-2.compute.internal/10.128.11.148:7337, creating a new one.
20/06/06 19:27:21 INFO Executor: Finished task 430.0 in stage 18.0 (TID 5741). 1923 bytes result sent to driver
20/06/06 19:27:21 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-148.us-west-2.compute.internal/10.128.11.148:7337 after 7 ms (0 ms spent in bootstraps)
20/06/06 19:27:21 INFO CoarseGrainedExecutorBackend: Got assigned task 5993
20/06/06 19:27:21 INFO Executor: Running task 29.0 in stage 19.0 (TID 5993)
20/06/06 19:27:21 INFO TransportClientFactory: Found inactive connection to ip-10-128-11-205.us-west-2.compute.internal/10.128.11.205:7337, creating a new one.
20/06/06 19:27:21 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-205.us-west-2.compute.internal/10.128.11.205:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:21 INFO TransportClientFactory: Found inactive connection to ip-10-128-11-42.us-west-2.compute.internal/10.128.11.42:7337, creating a new one.
20/06/06 19:27:21 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-42.us-west-2.compute.internal/10.128.11.42:7337 after 8 ms (0 ms spent in bootstraps)
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 7 remote fetches in 38 ms
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:21 INFO TransportClientFactory: Found inactive connection to ip-10-128-11-202.us-west-2.compute.internal/10.128.11.202:7337, creating a new one.
20/06/06 19:27:21 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-202.us-west-2.compute.internal/10.128.11.202:7337 after 3 ms (0 ms spent in bootstraps)
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 14 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 28.548548 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 41.393063 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 29.273026 ms
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 7, fetching them
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 7, fetching them
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:21 INFO TransportClientFactory: Found inactive connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:7337, creating a new one.
20/06/06 19:27:21 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-54.us-west-2.compute.internal/10.128.11.54:7337 after 30 ms (0 ms spent in bootstraps)
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 37 ms
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 58 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 40.77067 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 10.129841 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 8.37573 ms
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 8, fetching them
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 8, fetching them
20/06/06 19:27:21 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:21 INFO TransportClientFactory: Found inactive connection to ip-10-128-11-145.us-west-2.compute.internal/10.128.11.145:7337, creating a new one.
20/06/06 19:27:21 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-145.us-west-2.compute.internal/10.128.11.145:7337 after 8 ms (0 ms spent in bootstraps)
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 17 ms
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 16 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 23.7463 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 6.89338 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 13.055166 ms
20/06/06 19:27:21 INFO CodeGenerator: Code generated in 6.432064 ms
20/06/06 19:27:21 INFO Executor: Finished task 527.0 in stage 18.0 (TID 5838). 1923 bytes result sent to driver
20/06/06 19:27:21 INFO CoarseGrainedExecutorBackend: Got assigned task 5999
20/06/06 19:27:21 INFO Executor: Running task 67.0 in stage 19.0 (TID 5999)
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 12 remote fetches in 6 ms
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:21 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:27:22 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=7/000039_0, range: 0-40612, partition values: [2017,7,7]
20/06/06 19:27:23 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2017/month=7/day=7/000039_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40612, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:23 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:25 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=13/000038_0, range: 0-40609, partition values: [2018,3,13]
20/06/06 19:27:25 INFO CodeGenerator: Code generated in 6.331318 ms
20/06/06 19:27:25 INFO CodeGenerator: Code generated in 5.321106 ms
20/06/06 19:27:25 INFO CodeGenerator: Code generated in 5.191183 ms
20/06/06 19:27:25 INFO CodeGenerator: Code generated in 4.8952 ms
20/06/06 19:27:25 INFO CodeGenerator: Code generated in 5.017987 ms
20/06/06 19:27:26 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2018/month=3/day=13/000038_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false, true], offset: 0, length: 40609, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:26 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string,_col12:string>
20/06/06 19:27:26 INFO CodeGenerator: Code generated in 8.85095 ms
20/06/06 19:27:26 INFO CodeGenerator: Code generated in 5.901492 ms
20/06/06 19:27:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 9, fetching them
20/06/06 19:27:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 9, fetching them
20/06/06 19:27:26 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:27:26 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:27:26 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:26 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:26 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
20/06/06 19:27:26 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
20/06/06 19:27:26 INFO CodeGenerator: Code generated in 16.494433 ms
20/06/06 19:27:26 INFO CodeGenerator: Code generated in 9.866639 ms
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 10, fetching them
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:28 INFO TransportClientFactory: Found inactive connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:7337, creating a new one.
20/06/06 19:27:28 INFO TransportClientFactory: Successfully created connection to ip-10-128-11-116.us-west-2.compute.internal/10.128.11.116:7337 after 1 ms (0 ms spent in bootstraps)
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 7 ms
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 9 ms
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 0 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 15.300355 ms
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 8 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 6.279263 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 8.895585 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 9.383982 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 10.699111 ms
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 11, fetching them
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 11, fetching them
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-128-11-116.us-west-2.compute.internal:42673)
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 11, fetching them
20/06/06 19:27:28 INFO MapOutputTrackerWorker: Got the output locations
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks including 2 local blocks and 78 remote blocks
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Getting 78 non-empty blocks including 2 local blocks and 76 remote blocks
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks including 2 local blocks and 78 remote blocks
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 3 ms
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Started 37 remote fetches in 4 ms
20/06/06 19:27:28 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 4 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 13.171915 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 9.081465 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 11.250462 ms
20/06/06 19:27:28 INFO CodeGenerator: Code generated in 14.601691 ms
20/06/06 19:27:33 INFO FileScanRDD: Reading File path: s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=12/004241_0, range: 0-40605, partition values: [2016,1,12]
20/06/06 19:27:33 INFO ReaderImpl: Reading ORC rows from s3://imvudata/user/hive/warehouse/events_etl.db/event_ui_imvu_account_events/year=2016/month=1/day=12/004241_0 with {include: [true, false, true, false, false, true, false, false, false, false, false, true, false], offset: 0, length: 40605, sarg: leaf-0 = (IS_NULL customers_id), expr = (not leaf-0), columns: ['event_time', 'customers_id', 'client_session', 'user_agent', 'user_agent_platform', 'url', 'email', 'dob', 'country', 'avatarname', 'reg_token_type', 'is_internal_ip', 'registration_flow'], includeAcidColumns: true}
20/06/06 19:27:33 INFO RecordReaderImpl: Reader schema not provided -- using file schema struct<_col0:string,_col1:string,_col2:string,_col3:string,_col4:string,_col5:string,_col6:string,_col7:string,_col8:string,_col9:string,_col10:string,_col11:string>
20/06/06 19:27:35 INFO Executor: Finished task 1616.0 in stage 14.0 (TID 4434). 2548 bytes result sent to driver
20/06/06 19:27:35 INFO CoarseGrainedExecutorBackend: Got assigned task 6468
20/06/06 19:27:35 INFO Executor: Running task 140.0 in stage 19.0 (TID 6468)
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Started 13 remote fetches in 1 ms
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 43 ms
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Getting 81 non-empty blocks including 2 local blocks and 79 remote blocks
20/06/06 19:27:35 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 30 ms
20/06/06 19:27:45 INFO Executor: Finished task 25.0 in stage 19.0 (TID 5990). 14929 bytes result sent to driver
20/06/06 19:27:45 INFO CoarseGrainedExecutorBackend: Got assigned task 6530
20/06/06 19:27:45 INFO Executor: Running task 211.0 in stage 19.0 (TID 6530)
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 7 remote fetches in 2 ms
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 0 ms
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 21 ms
20/06/06 19:27:45 INFO Executor: Finished task 67.0 in stage 19.0 (TID 5999). 14929 bytes result sent to driver
20/06/06 19:27:45 INFO CoarseGrainedExecutorBackend: Got assigned task 6531
20/06/06 19:27:45 INFO Executor: Running task 212.0 in stage 19.0 (TID 6531)
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 11 remote fetches in 2 ms
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks including 1 local blocks and 79 remote blocks
20/06/06 19:27:45 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 7 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 15 ms
20/06/06 19:27:46 INFO Executor: Finished task 29.0 in stage 19.0 (TID 5993). 14929 bytes result sent to driver
20/06/06 19:27:46 INFO CoarseGrainedExecutorBackend: Got assigned task 6532
20/06/06 19:27:46 INFO Executor: Running task 220.0 in stage 19.0 (TID 6532)
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 76 non-empty blocks including 1 local blocks and 75 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 37 remote fetches in 2 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 16 remote fetches in 1 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 0 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 5 ms
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Getting 79 non-empty blocks including 2 local blocks and 77 remote blocks
20/06/06 19:27:46 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 2 ms
20/06/06 19:27:47 INFO Executor: Finished task 140.0 in stage 19.0 (TID 6468). 14929 bytes result sent to driver
20/06/06 19:27:47 INFO CoarseGrainedExecutorBackend: Got assigned task 6543
20/06/06 19:27:47 INFO Executor: Running task 253.0 in stage 19.0 (TID 6543)
20/06/06 19:27:47 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:47 INFO ShuffleBlockFetcherIterator: Started 11 remote fetches in 3 ms
20/06/06 19:27:47 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:47 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:27:47 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:47 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 8 ms
20/06/06 19:27:48 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:48 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 16 ms
20/06/06 19:27:48 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:48 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 22 ms
20/06/06 19:27:48 INFO ShuffleBlockFetcherIterator: Getting 79 non-empty blocks including 2 local blocks and 77 remote blocks
20/06/06 19:27:48 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 3 ms
20/06/06 19:27:57 INFO Executor: Finished task 211.0 in stage 19.0 (TID 6530). 14929 bytes result sent to driver
20/06/06 19:27:57 INFO CoarseGrainedExecutorBackend: Got assigned task 6586
20/06/06 19:27:57 INFO Executor: Running task 301.0 in stage 19.0 (TID 6586)
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Started 16 remote fetches in 39 ms
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 4 ms
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 18 ms
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Getting 82 non-empty blocks including 2 local blocks and 80 remote blocks
20/06/06 19:27:57 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 3 ms
20/06/06 19:27:58 INFO Executor: Finished task 220.0 in stage 19.0 (TID 6532). 14929 bytes result sent to driver
20/06/06 19:27:58 INFO CoarseGrainedExecutorBackend: Got assigned task 6589
20/06/06 19:27:58 INFO Executor: Running task 306.0 in stage 19.0 (TID 6589)
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 13 remote fetches in 2 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 1 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks including 2 local blocks and 78 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 11 ms
20/06/06 19:27:58 INFO Executor: Finished task 212.0 in stage 19.0 (TID 6531). 14929 bytes result sent to driver
20/06/06 19:27:58 INFO CoarseGrainedExecutorBackend: Got assigned task 6592
20/06/06 19:27:58 INFO Executor: Running task 345.0 in stage 19.0 (TID 6592)
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 18 remote fetches in 1 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 0 ms
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:27:58 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 2 ms
20/06/06 19:27:59 INFO ShuffleBlockFetcherIterator: Getting 82 non-empty blocks including 2 local blocks and 80 remote blocks
20/06/06 19:27:59 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 1 ms
20/06/06 19:28:00 INFO Executor: Finished task 253.0 in stage 19.0 (TID 6543). 14929 bytes result sent to driver
20/06/06 19:28:00 INFO CoarseGrainedExecutorBackend: Got assigned task 6600
20/06/06 19:28:00 INFO Executor: Running task 384.0 in stage 19.0 (TID 6600)
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Getting 400 non-empty blocks including 2 local blocks and 398 remote blocks
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Started 16 remote fetches in 11 ms
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 0 local blocks and 6 remote blocks
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 0 ms
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks including 1 local blocks and 5 remote blocks
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 14 ms
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Getting 83 non-empty blocks including 2 local blocks and 81 remote blocks
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Started 38 remote fetches in 1 ms
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Getting 79 non-empty blocks including 2 local blocks and 77 remote blocks
20/06/06 19:28:00 INFO ShuffleBlockFetcherIterator: Started 37 remote fetches in 6 ms
20/06/06 19:28:08 INFO Executor: Finished task 301.0 in stage 19.0 (TID 6586). 14929 bytes result sent to driver
20/06/06 19:28:08 INFO Executor: Finished task 306.0 in stage 19.0 (TID 6589). 14929 bytes result sent to driver
20/06/06 19:28:08 INFO Executor: Finished task 345.0 in stage 19.0 (TID 6592). 14929 bytes result sent to driver
20/06/06 19:28:10 INFO Executor: Finished task 384.0 in stage 19.0 (TID 6600). 14929 bytes result sent to driver
20/06/06 19:29:11 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/06/06 19:29:11 INFO DiskBlockManager: Shutdown hook called
20/06/06 19:29:11 INFO ShutdownHookManager: Shutdown hook called
